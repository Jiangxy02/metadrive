#!/usr/bin/env python
"""
å®˜æ–¹MetaDriveå•æ™ºèƒ½ä½“ç¯å¢ƒç¤ºä¾‹ + è§‚æµ‹çŠ¶æ€è®°å½•åŠŸèƒ½

åŸºäºåŸå§‹çš„drive_in_single_agent_env.pyï¼Œé›†æˆäº†è§‚æµ‹è®°å½•å™¨åŠŸèƒ½ï¼Œ
ç”¨äºè®°å½•å’Œåˆ†æè½¦è¾†åœ¨æ ‡å‡†MetaDriveç¯å¢ƒä¸­çš„è¡Œä¸ºè¡¨ç°ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
1. ä¿æŒåŸæœ‰çš„é”®ç›˜æ§åˆ¶å’Œè‡ªåŠ¨é©¾é©¶åŠŸèƒ½
2. é›†æˆè§‚æµ‹çŠ¶æ€è®°å½•å™¨ï¼Œè®°å½•æ¯ä¸€æ­¥çš„è¯¦ç»†æ•°æ®
3. æ”¯æŒlidarå’Œrgb_cameraä¸¤ç§è§‚æµ‹æ¨¡å¼
4. è‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
python drive_in_single_agent_env_with_recorder.py --observation lidar
python drive_in_single_agent_env_with_recorder.py --observation rgb_camera
"""
import argparse
import logging
import random
import sys
import os

import cv2
import numpy as np

from metadrive import MetaDriveEnv
from metadrive.component.sensors.rgb_camera import RGBCamera
from metadrive.constants import HELP_MESSAGE

# å¯¼å…¥è§‚æµ‹è®°å½•å™¨
from observation_recorder import ObservationRecorder


class MetaDriveWithRecorder:
    """
    å¸¦è§‚æµ‹è®°å½•åŠŸèƒ½çš„MetaDriveç¯å¢ƒåŒ…è£…å™¨
    """
    def __init__(self, config, enable_recording=True, session_name=None, max_steps=1000):
        self.env = MetaDriveEnv(config)
        self.enable_recording = enable_recording
        self.max_steps = max_steps
        self.step_count = 0
        
        # åˆå§‹åŒ–è§‚æµ‹è®°å½•å™¨
        if self.enable_recording:
            output_dir = "metadrive_official_logs"
            if session_name is None:
                session_name = "official_metadrive_analysis"
            self.recorder = ObservationRecorder(output_dir=output_dir, session_name=session_name)
            print(f"âœ… è§‚æµ‹è®°å½•å™¨å·²å¯ç”¨ï¼Œè¾“å‡ºç›®å½•ï¼š{output_dir}")
        else:
            self.recorder = None
    
    def reset(self, seed=None):
        """é‡ç½®ç¯å¢ƒ"""
        self.step_count = 0
        return self.env.reset(seed=seed)
    
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥å¹¶è®°å½•è§‚æµ‹æ•°æ®"""
        obs, reward, terminated, truncated, info = self.env.step(action)
        
        # è®°å½•è§‚æµ‹æ•°æ®
        if self.recorder and self.step_count < self.max_steps:
            # æ„é€ action_infoï¼ˆå®˜æ–¹ç¯å¢ƒæ²¡æœ‰æ˜ç¡®çš„æ§åˆ¶æ¨¡å¼ç®¡ç†å™¨ï¼‰
            action_info = {
                "source": "expert" if self.env.current_track_agent.expert_takeover else "manual",
                "success": True
            }
            
            # ä½¿ç”¨é€‚é…å™¨æ¨¡å¼è®°å½•æ•°æ®
            self.recorder.record_step(
                env=self._create_env_adapter(),
                action=action,
                action_info=action_info,
                obs=obs,
                reward=reward,
                info=info,
                step_count=self.step_count
            )
        
        self.step_count += 1
        return obs, reward, terminated, truncated, info
    
    def _create_env_adapter(self):
        """
        åˆ›å»ºç¯å¢ƒé€‚é…å™¨ï¼Œä½¿å®˜æ–¹MetaDriveEnvå…¼å®¹æˆ‘ä»¬çš„è®°å½•å™¨æ¥å£
        """
        class EnvAdapter:
            def __init__(self, metadrive_env):
                self.env = metadrive_env
                self.agent = metadrive_env.current_track_agent
                self.custom_destination = None  # å®˜æ–¹ç¯å¢ƒæ²¡æœ‰è‡ªå®šä¹‰ç›®æ ‡ç‚¹
            
            @property
            def enable_background_vehicles(self):
                return True  # å®˜æ–¹ç¯å¢ƒé»˜è®¤æœ‰èƒŒæ™¯è½¦è¾†
        
        return EnvAdapter(self.env)
    
    def render(self, **kwargs):
        """æ¸²æŸ“ç¯å¢ƒ"""
        return self.env.render(**kwargs)
    
    def close(self):
        """å…³é—­ç¯å¢ƒå¹¶ä¿å­˜è®°å½•"""
        if self.recorder:
            print(f"\nğŸ“Š æ­£åœ¨ä¿å­˜è§‚æµ‹è®°å½•... (å…±{self.step_count}æ­¥)")
            self.recorder.finalize_recording()
            print("âœ… è§‚æµ‹è®°å½•å·²ä¿å­˜å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        
        self.env.close()
    
    @property
    def current_track_agent(self):
        """è®¿é—®å½“å‰ä¸»è½¦"""
        return self.env.current_track_agent
    
    @property
    def agent(self):
        """è®¿é—®å½“å‰ä¸»è½¦ï¼ˆåˆ«åï¼‰"""
        return self.env.current_track_agent


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="MetaDriveå®˜æ–¹ç¤ºä¾‹ + è§‚æµ‹è®°å½•åŠŸèƒ½")
    parser.add_argument("--observation", type=str, default="lidar", choices=["lidar", "rgb_camera"])
    parser.add_argument("--enable_recording", action="store_true", default=True, help="å¯ç”¨è§‚æµ‹è®°å½•åŠŸèƒ½")
    parser.add_argument("--session_name", type=str, default="official_metadrive_analysis", help="è®°å½•ä¼šè¯åç§°")
    parser.add_argument("--max_steps", type=int, default=1000, help="æœ€å¤§è®°å½•æ­¥æ•°")
    args = parser.parse_args()
    
    # ç¯å¢ƒé…ç½®
    config = dict(
        # controller="steering_wheel",
        use_render=True,
        manual_control=True,
        traffic_density=0.1,
        num_scenarios=10000,
        random_agent_model=False,
        random_lane_width=True,
        random_lane_num=True,
        on_continuous_line_done=False,
        out_of_route_done=True,
        vehicle_config=dict(show_lidar=True, show_navi_mark=True, show_line_to_navi_mark=True),
        # debug=True,
        # debug_static_world=True,
        map=4,  # seven block
        start_seed=10,
    )
    
    # RGBç›¸æœºè§‚æµ‹é…ç½®
    if args.observation == "rgb_camera":
        config.update(
            dict(
                image_observation=True,
                sensors=dict(rgb_camera=(RGBCamera, 400, 300)),
                interface_panel=["rgb_camera", "dashboard"]
            )
        )
    
    # åˆ›å»ºå¸¦è®°å½•åŠŸèƒ½çš„ç¯å¢ƒ
    env = MetaDriveWithRecorder(
        config=config,
        enable_recording=args.enable_recording,
        session_name=args.session_name,
        max_steps=args.max_steps
    )
    
    print(f"\nğŸš— MetaDriveå®˜æ–¹ç¤ºä¾‹ + è§‚æµ‹è®°å½•åŠŸèƒ½")
    print(f"è§‚æµ‹æ¨¡å¼ï¼š{args.observation}")
    print(f"è§‚æµ‹è®°å½•ï¼š{'å¯ç”¨' if args.enable_recording else 'ç¦ç”¨'}")
    print(f"æœ€å¤§è®°å½•æ­¥æ•°ï¼š{args.max_steps}")
    print(f"ä¼šè¯åç§°ï¼š{args.session_name}")
    
    try:
        # é‡ç½®ç¯å¢ƒ
        o, _ = env.reset(seed=21)
        print(HELP_MESSAGE)
        
        # å¯ç”¨ä¸“å®¶æ¨¡å¼
        env.current_track_agent.expert_takeover = True
        
        # è§‚æµ‹ä¿¡æ¯
        if args.observation == "rgb_camera":
            assert isinstance(o, dict)
            print("è§‚æµ‹æ˜¯å­—å…¸æ ¼å¼ï¼ŒåŒ…å«numpyæ•°ç»„ï¼š", {k: v.shape for k, v in o.items()})
        else:
            assert isinstance(o, np.ndarray)
            print("è§‚æµ‹æ˜¯numpyæ•°ç»„ï¼Œå½¢çŠ¶ï¼š", o.shape)
        
        # ä¸»å¾ªç¯
        for i in range(1, args.max_steps + 1):
            # æ‰§è¡Œæ­¥éª¤
            o, r, tm, tc, info = env.step([0, 0])
            
            # æ¸²æŸ“
            env.render(
                text={
                    "Auto-Drive (Switch mode: T)": "on" if env.current_track_agent.expert_takeover else "off",
                    "Current Observation": args.observation,
                    "Keyboard Control": "W,A,S,D",
                    "Recording": "Enabled" if args.enable_recording else "Disabled",
                    "Step": f"{i}/{args.max_steps}",
                    "Position": f"({env.current_track_agent.position[0]:.1f}, {env.current_track_agent.position[1]:.1f})",
                    "Speed": f"{env.current_track_agent.speed:.1f} m/s",
                }
            )
            
            # æ‰“å°å¯¼èˆªä¿¡æ¯ï¼ˆæ¯10æ­¥ä¸€æ¬¡ï¼‰
            if i % 10 == 0:
                print(f"Step {i}: Navigation: {info.get('navigation_command', 'N/A')}, "
                      f"Position: ({env.current_track_agent.position[0]:.1f}, {env.current_track_agent.position[1]:.1f}), "
                      f"Speed: {env.current_track_agent.speed:.2f} m/s")
            
            # RGBç›¸æœºæ˜¾ç¤º
            if args.observation == "rgb_camera":
                cv2.imshow('RGB Image in Observation', o["image"][..., -1])
                cv2.waitKey(1)
            
            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç›®æ ‡æˆ–è¶…è¿‡æœ€å¤§æ­¥æ•°
            if (tm or tc) and info.get("arrive_dest", False):
                print(f"ğŸ¯ åˆ°è¾¾ç›®æ ‡ï¼é‡ç½®ç¯å¢ƒ...")
                env.reset(env.env.current_seed + 1)
                env.current_track_agent.expert_takeover = True
            elif i >= args.max_steps:
                print(f"ğŸ“ˆ è¾¾åˆ°æœ€å¤§è®°å½•æ­¥æ•° ({args.max_steps})ï¼Œåœæ­¢è®°å½•")
                break
                
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æ•°æ®...")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œé”™è¯¯ï¼š{e}")
    finally:
        env.close()
        print("\nğŸ ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main() 