"""
Episodeç®¡ç†å™¨ - è§£å†³è®­ç»ƒå¡æ­»é—®é¢˜

é—®é¢˜ï¼š
- PPOè®­ç»ƒå¡åœ¨åŒä¸€ä¸ªstepä¸åŠ¨
- ç¯å¢ƒæ— æ³•æ­£ç¡®ç»“æŸepisode
- ç¼ºå°‘å¼ºåˆ¶é‡ç½®æœºåˆ¶

è§£å†³æ–¹æ¡ˆï¼š
- æ·»åŠ å¤šç§ç»“æŸæ¡ä»¶æ£€æŸ¥
- å¼ºåˆ¶episodeè¶…æ—¶é‡ç½®
- ç¡®ä¿doneçŠ¶æ€æ­£ç¡®ä¼ é€’
"""

import numpy as np
from typing import Dict, Any, Tuple, Optional
import time


class EpisodeManager:
    """
    Episodeç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    1. ç›‘æ§episodeçŠ¶æ€
    2. å¼ºåˆ¶è¶…æ—¶é‡ç½®
    3. ç¡®ä¿doneæ¡ä»¶æ­£ç¡®è§¦å‘
    4. æä¾›è°ƒè¯•ä¿¡æ¯
    """
    
    def __init__(self, 
                 max_episode_steps: int = 1000,
                 max_episode_time: float = 300.0,  # 5åˆ†é’Ÿè¶…æ—¶
                 force_reset_threshold: int = 1500,  # å¼ºåˆ¶é‡ç½®é˜ˆå€¼
                 stale_detection_steps: int = 50):   # åœæ»æ£€æµ‹æ­¥æ•°
        
        self.max_episode_steps = max_episode_steps
        self.max_episode_time = max_episode_time
        self.force_reset_threshold = force_reset_threshold
        self.stale_detection_steps = stale_detection_steps
        
        # çŠ¶æ€è·Ÿè¸ª
        self.reset_episode_state()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_episodes = 0
        self.forced_resets = 0
        self.timeout_resets = 0
        self.stale_resets = 0
        
        print(f"ğŸ® EpisodeManager åˆå§‹åŒ–:")
        print(f"   æœ€å¤§æ­¥æ•°: {max_episode_steps}")
        print(f"   è¶…æ—¶æ—¶é—´: {max_episode_time}s")
        print(f"   å¼ºåˆ¶é‡ç½®é˜ˆå€¼: {force_reset_threshold}")
    
    def reset_episode_state(self):
        """é‡ç½®episodeçŠ¶æ€"""
        self.episode_start_time = time.time()
        self.episode_step_count = 0
        self.last_position = None
        self.position_history = []
        self.stuck_counter = 0
        self.last_reward = 0.0
        self.cumulative_reward = 0.0
        
    def should_end_episode(self, 
                          obs: np.ndarray,
                          reward: float,
                          done: bool,
                          info: Dict[str, Any],
                          agent_position: Optional[Tuple[float, float]] = None) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸepisode
        
        Returns:
            (should_end, reason)
        """
        self.episode_step_count += 1
        self.cumulative_reward += reward
        
        # 1. åŸå§‹doneçŠ¶æ€
        if done:
            return True, "original_done"
        
        # 2. æ­¥æ•°è¶…é™
        if self.episode_step_count >= self.max_episode_steps:
            return True, "max_steps"
        
        # 3. æ—¶é—´è¶…æ—¶
        episode_time = time.time() - self.episode_start_time
        if episode_time > self.max_episode_time:
            self.timeout_resets += 1
            return True, f"timeout_{episode_time:.1f}s"
        
        # 4. å¼ºåˆ¶é‡ç½®ï¼ˆé˜²æ­¢æ­»é”ï¼‰
        if self.episode_step_count >= self.force_reset_threshold:
            self.forced_resets += 1
            return True, f"force_reset_{self.episode_step_count}"
        
        # 5. åœæ»æ£€æµ‹ï¼ˆä½ç½®ä¸å˜ï¼‰
        if agent_position is not None:
            self.position_history.append(agent_position)
            if len(self.position_history) > self.stale_detection_steps:
                self.position_history.pop(0)
                
                # æ£€æŸ¥æ˜¯å¦åœ¨åŸåœ°ä¸åŠ¨
                if len(self.position_history) == self.stale_detection_steps:
                    positions = np.array(self.position_history)
                    position_variance = np.var(positions, axis=0)
                    
                    # å¦‚æœä½ç½®æ–¹å·®å¾ˆå°ï¼Œè¯´æ˜åœ¨åŸåœ°æ‰“è½¬
                    if np.all(position_variance < 0.1):  # æ–¹å·®é˜ˆå€¼
                        self.stale_resets += 1
                        return True, f"stale_position_var_{position_variance.max():.4f}"
        
        # 6. æ£€æŸ¥rewardå¼‚å¸¸
        if np.isnan(reward) or np.isinf(reward):
            return True, f"invalid_reward_{reward}"
        
        # 7. æ£€æŸ¥obså¼‚å¸¸
        if np.any(np.isnan(obs)) or np.any(np.isinf(obs)):
            return True, "invalid_observation"
        
        return False, "continue"
    
    def on_episode_end(self, reason: str):
        """episodeç»“æŸæ—¶è°ƒç”¨"""
        self.total_episodes += 1
        episode_time = time.time() - self.episode_start_time
        
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        if self.total_episodes % 10 == 0 or reason.startswith(("timeout", "force", "stale")):
            print(f"ğŸ“Š Episode {self.total_episodes} ç»“æŸ: {reason}")
            print(f"   æ­¥æ•°: {self.episode_step_count}")
            print(f"   æ—¶é—´: {episode_time:.1f}s")
            print(f"   ç´¯ç§¯å¥–åŠ±: {self.cumulative_reward:.2f}")
            if reason.startswith(("timeout", "force", "stale")):
                print(f"   âš ï¸ å¼‚å¸¸ç»“æŸåŸå› : {reason}")
        
        # é‡ç½®çŠ¶æ€
        self.reset_episode_state()
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_episodes": self.total_episodes,
            "forced_resets": self.forced_resets,
            "timeout_resets": self.timeout_resets,
            "stale_resets": self.stale_resets,
            "current_episode_steps": self.episode_step_count,
            "current_episode_time": time.time() - self.episode_start_time,
        }


class EpisodeManagedEnv:
    """
    æ”¯æŒEpisodeç®¡ç†çš„ç¯å¢ƒæ··å…¥ç±»
    """
    
    def __init__(self, *args, **kwargs):
        # æå–episodeç®¡ç†å™¨é…ç½®
        episode_config = {
            "max_episode_steps": kwargs.pop("max_episode_steps", 1000),
            "max_episode_time": kwargs.pop("max_episode_time", 300.0),
            "force_reset_threshold": kwargs.pop("force_reset_threshold", 1500),
            "stale_detection_steps": kwargs.pop("stale_detection_steps", 50),
        }
        
        # åˆå§‹åŒ–çˆ¶ç±»
        super().__init__(*args, **kwargs)
        
        # åˆ›å»ºepisodeç®¡ç†å™¨
        self.episode_manager = EpisodeManager(**episode_config)
        
        print("ğŸ® EpisodeManagedEnv å·²å¯ç”¨")
    
    def reset(self, **kwargs):
        """é‡ç½®ç¯å¢ƒæ—¶é‡ç½®episodeç®¡ç†å™¨"""
        # é‡ç½®episodeç®¡ç†å™¨
        self.episode_manager.reset_episode_state()
        
        # è°ƒç”¨çˆ¶ç±»reset
        result = super().reset(**kwargs)
        
        return result
    
    def step(self, action):
        """æ­¥éª¤æ‰§è¡Œæ—¶æ£€æŸ¥episodeç»“æŸæ¡ä»¶"""
        # æ‰§è¡ŒåŸå§‹æ­¥éª¤
        result = super().step(action)
        
        # è§£æç»“æœ
        if len(result) == 4:
            obs, reward, done, info = result
            terminated = truncated = done
        else:
            obs, reward, terminated, truncated, info = result
            done = terminated or truncated
        
        # è·å–agentä½ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        agent_position = None
        if hasattr(self, 'agent') and hasattr(self.agent, 'position'):
            agent_position = tuple(self.agent.position[:2])
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸepisode
        should_end, reason = self.episode_manager.should_end_episode(
            obs, reward, done, info, agent_position
        )
        
        # å¦‚æœéœ€è¦å¼ºåˆ¶ç»“æŸ
        if should_end and not done:
            print(f"ğŸ”„ å¼ºåˆ¶ç»“æŸepisode: {reason}")
            done = terminated = truncated = True
            info["forced_termination"] = True
            info["termination_reason"] = reason
        
        # å¦‚æœepisodeç»“æŸï¼Œé€šçŸ¥ç®¡ç†å™¨
        if done:
            self.episode_manager.on_episode_end(reason if should_end else "natural")
        
        # æ·»åŠ episodeç»Ÿè®¡åˆ°info
        info.update(self.episode_manager.get_statistics())
        
        # è¿”å›ç»“æœ
        if len(result) == 4:
            return obs, reward, done, info
        else:
            return obs, reward, terminated, truncated, info


def add_episode_management(env_class):
    """
    è£…é¥°å™¨ï¼šä¸ºä»»ä½•ç¯å¢ƒç±»æ·»åŠ episodeç®¡ç†åŠŸèƒ½
    
    ç”¨æ³•:
        @add_episode_management
        class MyEnv(SomeBaseEnv):
            pass
    """
    
    class ManagedEnv(EpisodeManagedEnv, env_class):
        """å¸¦episodeç®¡ç†çš„ç¯å¢ƒ"""
        pass
    
    # ä¿æŒåŸæœ‰ç±»å
    ManagedEnv.__name__ = f"Managed{env_class.__name__}"
    ManagedEnv.__qualname__ = f"Managed{env_class.__qualname__}"
    
    return ManagedEnv


# === ä½¿ç”¨ç¤ºä¾‹ ===
if __name__ == "__main__":
    print("Episodeç®¡ç†å™¨æµ‹è¯•:")
    
    manager = EpisodeManager()
    
    # æ¨¡æ‹Ÿepisode
    for step in range(100):
        obs = np.random.randn(10)
        reward = np.random.randn()
        done = False
        info = {}
        position = (step * 0.1, 0)  # ç¼“æ…¢ç§»åŠ¨
        
        should_end, reason = manager.should_end_episode(
            obs, reward, done, info, position
        )
        
        if should_end:
            print(f"Episodeåœ¨æ­¥éª¤{step}ç»“æŸ: {reason}")
            manager.on_episode_end(reason)
            break
    
    print("\nç»Ÿè®¡ä¿¡æ¯:")
    stats = manager.get_statistics()
    for k, v in stats.items():
        print(f"  {k}: {v}") 