# MetaDrive State çŠ¶æ€ä¿¡æ¯è·å–æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

MetaDriveç¯å¢ƒä¸­ï¼Œè½¦è¾†çš„çœŸå®ç‰©ç†çŠ¶æ€ï¼ˆStateï¼‰ä¸ç»è¿‡å¤„ç†çš„è§‚æµ‹å‘é‡ï¼ˆObservationï¼‰æ˜¯ä¸¤ä¸ªä¸åŒçš„æ¦‚å¿µã€‚æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•è·å–è½¦è¾†çš„åŸå§‹çŠ¶æ€ä¿¡æ¯ï¼Œä»¥åŠè¿™äº›çŠ¶æ€ä¿¡æ¯çš„å«ä¹‰å’Œç”¨é€”ã€‚

## ğŸ” State vs Observation åŒºåˆ«

### Stateï¼ˆçŠ¶æ€ï¼‰
- **å®šä¹‰**ï¼šè½¦è¾†åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„çœŸå®çŠ¶æ€
- **ç‰¹ç‚¹**ï¼šæœªç»å½’ä¸€åŒ–ï¼Œä¿æŒç‰©ç†å•ä½å’ŒçœŸå®æ•°å€¼
- **ç”¨é€”**ï¼šç”¨äºç‰©ç†ä»¿çœŸã€ç¢°æ’æ£€æµ‹ã€ç²¾ç¡®æ§åˆ¶ç­‰

### Observationï¼ˆè§‚æµ‹ï¼‰
- **å®šä¹‰**ï¼šç»è¿‡å¤„ç†ã€å½’ä¸€åŒ–çš„æ„ŸçŸ¥ä¿¡æ¯
- **ç‰¹ç‚¹**ï¼šå½’ä¸€åŒ–åˆ°[0,1]åŒºé—´ï¼Œé€‚åˆæœºå™¨å­¦ä¹ æ¨¡å‹
- **ç”¨é€”**ï¼šä½œä¸ºæ™ºèƒ½ä½“çš„è¾“å…¥ï¼Œç”¨äºå†³ç­–å’Œå­¦ä¹ 

## ğŸš— è½¦è¾†çŠ¶æ€ä¿¡æ¯è¯¦è§£

### 1. åŸºç¡€è¿åŠ¨çŠ¶æ€

#### ä½ç½®ä¿¡æ¯
```python
# è·å–æ–¹å¼
position = env.agent.position  # è¿”å› [x, y] åæ ‡
x = env.agent.position[0]      # Xåæ ‡ (ç±³)
y = env.agent.position[1]      # Yåæ ‡ (ç±³)

# æ•°æ®ç±»å‹
# position: numpy.ndarray, shape=(2,)
# åæ ‡ç³»: MetaDriveä¸–ç•Œåæ ‡ç³»ï¼Œå•ä½ä¸ºç±³
# ç¤ºä¾‹: [200.5, 7.2] è¡¨ç¤ºè½¦è¾†åœ¨(200.5m, 7.2m)ä½ç½®
```

#### é€Ÿåº¦ä¿¡æ¯
```python
# é€Ÿåº¦å¤§å°
speed = env.agent.speed        # æ ‡é‡é€Ÿåº¦ (m/s)

# é€Ÿåº¦çŸ¢é‡
velocity = env.agent.velocity  # è¿”å› [vx, vy] é€Ÿåº¦çŸ¢é‡
vx = env.agent.velocity[0]     # Xæ–¹å‘é€Ÿåº¦åˆ†é‡ (m/s)
vy = env.agent.velocity[1]     # Yæ–¹å‘é€Ÿåº¦åˆ†é‡ (m/s)

# æ•°æ®ç±»å‹
# speed: float, éè´Ÿå€¼
# velocity: numpy.ndarray, shape=(2,)
# ç¤ºä¾‹: speed=15.3 è¡¨ç¤ºè½¦é€Ÿ15.3ç±³/ç§’
#       velocity=[12.2, 9.1] è¡¨ç¤ºé€Ÿåº¦çŸ¢é‡
```

#### æœå‘ä¿¡æ¯
```python
# è½¦è¾†æœå‘è§’åº¦
heading = env.agent.heading_theta  # æœå‘è§’ (å¼§åº¦)

# æ•°æ®ç±»å‹
# heading_theta: float
# èŒƒå›´: [-Ï€, Ï€]
# è¯´æ˜: 0è¡¨ç¤ºæ­£ä¸œæ–¹å‘ï¼ŒÏ€/2è¡¨ç¤ºæ­£åŒ—æ–¹å‘
# ç¤ºä¾‹: heading=1.57 è¡¨ç¤ºæœå‘åŒ—æ–¹(Ï€/2å¼§åº¦)
```

### 2. è½¦é“å’Œé“è·¯ä¿¡æ¯

#### è½¦é“çŠ¶æ€
```python
# æ˜¯å¦åœ¨è½¦é“ä¸Š
on_lane = env.agent.on_lane           # bool

# æ˜¯å¦å‡ºç•Œ
out_of_road = env.agent.out_of_road   # bool

# åˆ°è½¦é“è¾¹ç•Œçš„è·ç¦»
dist_to_left = env.agent.dist_to_left_side    # åˆ°å·¦ä¾§è¾¹ç•Œè·ç¦» (ç±³)
dist_to_right = env.agent.dist_to_right_side  # åˆ°å³ä¾§è¾¹ç•Œè·ç¦» (ç±³)

# æ•°æ®ç±»å‹å’Œå«ä¹‰
# on_lane: Trueè¡¨ç¤ºåœ¨æœ‰æ•ˆè½¦é“ä¸Šï¼ŒFalseè¡¨ç¤ºä¸åœ¨è½¦é“ä¸Š
# out_of_road: Trueè¡¨ç¤ºè½¦è¾†å·²å‡ºç•Œ
# dist_to_left/right: float, æ­£å€¼è¡¨ç¤ºè·ç¦»ï¼Œå•ä½ä¸ºç±³
```

#### è½¦é“å‚è€ƒä¿¡æ¯
```python
# å½“å‰è½¦é“
current_lane = env.agent.lane         # å½“å‰æ‰€åœ¨è½¦é“å¯¹è±¡

# è½¦é“ä¸­å¿ƒçº¿ä½ç½®
if current_lane:
    # è·å–è½¦é“çš„å±€éƒ¨åæ ‡
    longitudinal, lateral = current_lane.local_coordinates(env.agent.position)
    # longitudinal: æ²¿è½¦é“æ–¹å‘çš„è·ç¦»
    # lateral: ç›¸å¯¹è½¦é“ä¸­å¿ƒçº¿çš„æ¨ªå‘åç§»
```

### 3. ç¢°æ’çŠ¶æ€ä¿¡æ¯

```python
# å„ç§ç¢°æ’çŠ¶æ€
crash_vehicle = env.agent.crash_vehicle     # æ˜¯å¦æ’è½¦
crash_object = env.agent.crash_object       # æ˜¯å¦æ’ç‰©ä½“
crash_sidewalk = env.agent.crash_sidewalk   # æ˜¯å¦æ’äººè¡Œé“

# æ•°æ®ç±»å‹
# æ‰€æœ‰ç¢°æ’çŠ¶æ€: bool
# Trueè¡¨ç¤ºå‘ç”Ÿå¯¹åº”ç±»å‹çš„ç¢°æ’ï¼ŒFalseè¡¨ç¤ºæ— ç¢°æ’
```

### 4. å¯¼èˆªä¿¡æ¯

```python
# å¯¼èˆªæ¨¡å—
navigation = env.agent.navigation

# å¯¼èˆªä¿¡æ¯
if navigation:
    # è·å–å¯¼èˆªè·¯å¾„ä¿¡æ¯
    navi_info = navigation.get_navi_info()  # 10ç»´å¯¼èˆªå‘é‡
    
    # å½“å‰è·¯å¾„
    current_lanes = navigation.current_ref_lanes
    
    # ç›®æ ‡ç‚¹ä¿¡æ¯
    destination = navigation.final_lane
    
    # è·¯å¾„å®Œæˆåº¦
    route_completion = navigation.route_completion
```

## ğŸ”§ çŠ¶æ€ä¿¡æ¯è·å–æ–¹æ³•

### æ–¹æ³•1ï¼šç›´æ¥è®¿é—®å±æ€§

```python
def get_vehicle_state(env):
    """è·å–è½¦è¾†å®Œæ•´çŠ¶æ€ä¿¡æ¯"""
    agent = env.agent
    
    state_info = {
        # åŸºç¡€è¿åŠ¨ä¿¡æ¯
        'position': {
            'x': float(agent.position[0]),
            'y': float(agent.position[1])
        },
        'velocity': {
            'speed': float(agent.speed),
            'vx': float(agent.velocity[0]),
            'vy': float(agent.velocity[1])
        },
        'orientation': {
            'heading': float(agent.heading_theta)
        },
        
        # è½¦é“ä¿¡æ¯
        'lane_info': {
            'on_lane': bool(agent.on_lane),
            'out_of_road': bool(agent.out_of_road),
            'dist_to_left': float(agent.dist_to_left_side),
            'dist_to_right': float(agent.dist_to_right_side)
        },
        
        # ç¢°æ’çŠ¶æ€
        'collision': {
            'crash_vehicle': bool(agent.crash_vehicle),
            'crash_object': bool(agent.crash_object), 
            'crash_sidewalk': bool(agent.crash_sidewalk)
        }
    }
    
    return state_info

# ä½¿ç”¨ç¤ºä¾‹
env = TrajectoryReplayEnvCognitive(...)
obs = env.reset()
state = get_vehicle_state(env)
print(f"è½¦è¾†ä½ç½®: ({state['position']['x']:.2f}, {state['position']['y']:.2f})")
print(f"è½¦è¾†é€Ÿåº¦: {state['velocity']['speed']:.2f} m/s")
```

### æ–¹æ³•2ï¼šä½¿ç”¨getattrå®‰å…¨è®¿é—®

```python
def safe_get_vehicle_state(env):
    """å®‰å…¨è·å–è½¦è¾†çŠ¶æ€ï¼ˆå¤„ç†å¯èƒ½ä¸å­˜åœ¨çš„å±æ€§ï¼‰"""
    agent = env.agent
    
    state_info = {
        # ä½ç½®å’Œè¿åŠ¨
        'pos_x': float(getattr(agent, 'position', [0, 0])[0]),
        'pos_y': float(getattr(agent, 'position', [0, 0])[1]),
        'speed': float(getattr(agent, 'speed', 0.0)),
        'heading': float(getattr(agent, 'heading_theta', 0.0)),
        'velocity_x': float(getattr(agent, 'velocity', [0, 0])[0]),
        'velocity_y': float(getattr(agent, 'velocity', [0, 0])[1]),
        
        # è½¦é“å’Œé“è·¯ä¿¡æ¯
        'on_lane': getattr(agent, 'on_lane', None),
        'out_of_road': getattr(agent, 'out_of_road', None),
        'dist_to_left_side': getattr(agent, 'dist_to_left_side', None),
        'dist_to_right_side': getattr(agent, 'dist_to_right_side', None),
        
        # ç¢°æ’çŠ¶æ€
        'crash_vehicle': getattr(agent, 'crash_vehicle', None),
        'crash_object': getattr(agent, 'crash_object', None),
        'crash_sidewalk': getattr(agent, 'crash_sidewalk', None),
    }
    
    return state_info
```

### æ–¹æ³•3ï¼šå®æ—¶çŠ¶æ€ç›‘æ§

```python
class VehicleStateMonitor:
    """è½¦è¾†çŠ¶æ€å®æ—¶ç›‘æ§å™¨"""
    
    def __init__(self, env):
        self.env = env
        self.state_history = []
    
    def record_current_state(self, step_count=None):
        """è®°å½•å½“å‰çŠ¶æ€"""
        agent = self.env.agent
        
        current_state = {
            'step': step_count,
            'timestamp': time.time(),
            'simulation_time': getattr(self.env, '_simulation_time', 0.0),
            
            # æ ¸å¿ƒçŠ¶æ€
            'position': list(agent.position),
            'speed': float(agent.speed),
            'heading': float(agent.heading_theta),
            'velocity': list(agent.velocity),
            
            # è½¦é“çŠ¶æ€
            'on_lane': bool(agent.on_lane),
            'out_of_road': bool(agent.out_of_road),
            'dist_to_left': float(agent.dist_to_left_side),
            'dist_to_right': float(agent.dist_to_right_side),
            
            # ç¢°æ’æ£€æµ‹
            'crash_vehicle': bool(agent.crash_vehicle),
            'crash_object': bool(agent.crash_object),
            'crash_sidewalk': bool(agent.crash_sidewalk)
        }
        
        self.state_history.append(current_state)
        return current_state
    
    def get_state_changes(self):
        """è·å–çŠ¶æ€å˜åŒ–ä¿¡æ¯"""
        if len(self.state_history) < 2:
            return None
            
        prev_state = self.state_history[-2]
        curr_state = self.state_history[-1]
        
        changes = {
            'position_change': np.linalg.norm(
                np.array(curr_state['position']) - np.array(prev_state['position'])
            ),
            'speed_change': curr_state['speed'] - prev_state['speed'],
            'heading_change': curr_state['heading'] - prev_state['heading'],
            'time_delta': curr_state['simulation_time'] - prev_state['simulation_time']
        }
        
        return changes

# ä½¿ç”¨ç¤ºä¾‹
env = TrajectoryReplayEnvCognitive(...)
monitor = VehicleStateMonitor(env)

obs = env.reset()
for step in range(100):
    action = [0.0, 0.5]  # ç¤ºä¾‹åŠ¨ä½œ
    obs, reward, done, info = env.step(action)
    
    # è®°å½•å½“å‰çŠ¶æ€
    state = monitor.record_current_state(step)
    print(f"Step {step}: Position=({state['position'][0]:.2f}, {state['position'][1]:.2f}), "
          f"Speed={state['speed']:.2f}")
    
    # åˆ†æçŠ¶æ€å˜åŒ–
    if step > 0:
        changes = monitor.get_state_changes()
        print(f"  ä½ç½®å˜åŒ–: {changes['position_change']:.3f}m, "
              f"é€Ÿåº¦å˜åŒ–: {changes['speed_change']:.3f}m/s")
    
    if done:
        break
```

## ğŸ“Š Stateä¸Observationçš„å¯¹åº”å…³ç³»

```python
def compare_state_and_observation(env):
    """å¯¹æ¯”çœŸå®çŠ¶æ€å’Œè§‚æµ‹å‘é‡"""
    # è·å–åŸå§‹çŠ¶æ€
    agent = env.agent
    true_state = {
        'position_x': agent.position[0],
        'position_y': agent.position[1], 
        'speed': agent.speed,
        'heading': agent.heading_theta,
        'dist_to_left': agent.dist_to_left_side,
        'dist_to_right': agent.dist_to_right_side
    }
    
    # è·å–è§‚æµ‹å‘é‡
    obs = env._get_observation()
    
    # å¯¹æ¯”åˆ†æ
    print("=== State vs Observation å¯¹æ¯” ===")
    print(f"çœŸå®ä½ç½®: ({true_state['position_x']:.3f}, {true_state['position_y']:.3f})")
    print(f"è§‚æµ‹ä½ç½®: obs[0]={obs[0]:.3f}, obs[1]={obs[1]:.3f}")
    print(f"  è¯´æ˜: è§‚æµ‹å€¼æ˜¯å½’ä¸€åŒ–çš„é“è·¯è¾¹ç•Œè·ç¦»ï¼Œä¸æ˜¯ç»å¯¹ä½ç½®")
    
    print(f"\nçœŸå®é€Ÿåº¦: {true_state['speed']:.3f} m/s")
    print(f"è§‚æµ‹é€Ÿåº¦: obs[3]={obs[3]:.3f}")
    print(f"  è¯´æ˜: è§‚æµ‹å€¼æ˜¯å½’ä¸€åŒ–çš„é€Ÿåº¦")
    
    print(f"\nçœŸå®æœå‘: {true_state['heading']:.3f} rad")
    print(f"è§‚æµ‹æœå‘å·®: obs[2]={obs[2]:.3f}")
    print(f"  è¯´æ˜: è§‚æµ‹å€¼æ˜¯ä¸è½¦é“æœå‘çš„å·®å¼‚ï¼Œä¸æ˜¯ç»å¯¹æœå‘")
    
    print(f"\nçœŸå®è¾¹ç•Œè·ç¦»: å·¦={true_state['dist_to_left']:.3f}m, å³={true_state['dist_to_right']:.3f}m")
    print(f"è§‚æµ‹è¾¹ç•Œè·ç¦»: obs[0]={obs[0]:.3f}, obs[1]={obs[1]:.3f}")
    print(f"  è¯´æ˜: è§‚æµ‹å€¼æ˜¯å½’ä¸€åŒ–åçš„è¾¹ç•Œè·ç¦»")
    
    return true_state, obs
```

## ğŸ¯ è®¤çŸ¥æ¨¡å—ä¸­çš„åº”ç”¨

```python
def get_ego_state_for_cognitive_modules(env):
    """ä¸ºè®¤çŸ¥æ¨¡å—è·å–ä¸»è½¦çŠ¶æ€ä¿¡æ¯"""
    agent = env.agent
    
    # è®¤çŸ¥æ¨¡å—éœ€è¦çš„å…³é”®çŠ¶æ€ä¿¡æ¯
    ego_state = {
        # ç”¨äºæ„ŸçŸ¥æ¨¡å—çš„ä½ç½®ä¿¡æ¯
        'true_position': np.array([agent.position[0], agent.position[1]]),
        
        # ç”¨äºè®¡ç®—ä¸»è½¦-ç›®æ ‡è½¦è·ç¦»
        'position_x': agent.position[0],
        'position_y': agent.position[1],
        
        # ç”¨äºå»¶è¿Ÿæ¨¡å—çš„åŠ¨åŠ›å­¦ä¿¡æ¯
        'speed': agent.speed,
        'heading': agent.heading_theta,
        'velocity': np.array([agent.velocity[0], agent.velocity[1]]),
        
        # ç”¨äºå®‰å…¨è¯„ä¼°çš„è½¦é“ä¿¡æ¯
        'on_lane': agent.on_lane,
        'out_of_road': agent.out_of_road,
        'dist_to_left_side': agent.dist_to_left_side,
        'dist_to_right_side': agent.dist_to_right_side
    }
    
    return ego_state

# åœ¨è®¤çŸ¥æ¨¡å—ä¸­çš„ä½¿ç”¨ç¤ºä¾‹
class CognitivePerceptionModule:
    def process_observation(self, obs, env):
        # è·å–çœŸå®çš„ä¸»è½¦çŠ¶æ€
        ego_state = get_ego_state_for_cognitive_modules(env)
        true_x, true_y = ego_state['true_position']
        
        # åŸºäºçœŸå®ä½ç½®è®¡ç®—æ„ŸçŸ¥å™ªå£°
        sigma_x = self.calculate_dynamic_sigma(ego_state)
        
        # å¤„ç†è§‚æµ‹...
        return processed_obs
```

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

### 1. åæ ‡ç³»ç»Ÿ
- **MetaDriveåæ ‡ç³»**: å³æ‰‹åæ ‡ç³»ï¼ŒXè½´å‘å‰ï¼ŒYè½´å‘å·¦ï¼ŒZè½´å‘ä¸Š
- **åŸç‚¹ä½ç½®**: é€šå¸¸ä»¥åœ°å›¾ä¸­å¿ƒæˆ–èµ·å§‹ç‚¹ä¸ºåŸç‚¹
- **å•ä½**: æ‰€æœ‰è·ç¦»å•ä½ä¸ºç±³ï¼Œè§’åº¦å•ä½ä¸ºå¼§åº¦

### 2. æ•°æ®ç±»å‹
- **ä½ç½®å’Œé€Ÿåº¦**: numpy.ndarray æˆ– float
- **å¸ƒå°”çŠ¶æ€**: bool ç±»å‹
- **è§’åº¦**: floatï¼ŒèŒƒå›´ [-Ï€, Ï€]

### 3. è®¿é—®å®‰å…¨æ€§
- ä½¿ç”¨ `getattr()` å¯ä»¥å®‰å…¨è®¿é—®å¯èƒ½ä¸å­˜åœ¨çš„å±æ€§
- æŸäº›å±æ€§åœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¯èƒ½ä¸º `None`
- å»ºè®®åœ¨è®¿é—®å‰å…ˆæ£€æŸ¥å±æ€§æ˜¯å¦å­˜åœ¨

### 4. æ€§èƒ½è€ƒè™‘
- çŠ¶æ€ä¿¡æ¯è·å–æ˜¯è½»é‡çº§æ“ä½œ
- å¯ä»¥åœ¨æ¯ä¸ªä»¿çœŸæ­¥éª¤ä¸­å®‰å…¨è°ƒç”¨
- é¿å…é¢‘ç¹çš„æ·±æ‹·è´æ“ä½œ

## ğŸ“ æ€»ç»“

MetaDriveçš„çŠ¶æ€ä¿¡æ¯æä¾›äº†è½¦è¾†çš„çœŸå®ç‰©ç†çŠ¶æ€ï¼Œè¿™äº›ä¿¡æ¯å¯¹äºï¼š
- **ç²¾ç¡®æ§åˆ¶**: éœ€è¦ç‰©ç†å•ä½çš„çœŸå®æ•°å€¼
- **ç¢°æ’æ£€æµ‹**: éœ€è¦å‡†ç¡®çš„ä½ç½®å’Œé€Ÿåº¦ä¿¡æ¯  
- **æ€§èƒ½åˆ†æ**: éœ€è¦æœªç»å¤„ç†çš„åŸå§‹æ•°æ®
- **è®¤çŸ¥å»ºæ¨¡**: éœ€è¦çœŸå®çŠ¶æ€ç”¨äºè®¡ç®—æ„ŸçŸ¥åå·®

ä¸å½’ä¸€åŒ–çš„è§‚æµ‹å‘é‡ç›¸æ¯”ï¼ŒçŠ¶æ€ä¿¡æ¯ä¿æŒäº†åŸå§‹çš„ç‰©ç†æ„ä¹‰ï¼Œæ˜¯å®ç°é«˜ç²¾åº¦ä»¿çœŸå’Œåˆ†æçš„é‡è¦åŸºç¡€ã€‚ 