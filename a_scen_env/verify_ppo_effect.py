#!/usr/bin/env python3

import sys
import os
import numpy as np
sys.path.append('.')

from trajectory_replay import TrajectoryReplayEnv
from trajectory_loader import load_trajectory

def verify_ppo_effect():
    print("ğŸ” éªŒè¯PPOå¯¹ä¸»è½¦é€Ÿåº¦çš„å½±å“")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    csv_path = "scenario_vehicles_8_0_1_2_3_4_5_6_7_test3_20250304_162012_row070_filtered.csv"
    traj_data = load_trajectory(csv_path=csv_path, normalize_position=False, max_duration=5, 
                               use_original_position=False, translate_to_origin=True, target_fps=50.0)
    
    # åˆ›å»ºç¯å¢ƒ
    env = TrajectoryReplayEnv(traj_data, config=dict(use_render=False))
    env.reset()
    
    print(f"\nå®éªŒ1: ä½¿ç”¨é›¶åŠ¨ä½œ [0, 0]")
    initial_pos = [env.agent.position[0], env.agent.position[1]]
    
    for step in range(3):
        obs, reward, done, info = env.step([0, 0])  # é›¶åŠ¨ä½œ
        new_pos = [env.agent.position[0], env.agent.position[1]]
        distance = ((new_pos[0] - initial_pos[0])**2 + (new_pos[1] - initial_pos[1])**2)**0.5
        print(f"  æ­¥éª¤ {step+1}: åŠ¨ä½œ=[0,0], ç§»åŠ¨={distance:.3f}m, é€Ÿåº¦={env.agent.speed:.2f}m/s")
    
    # é‡ç½®ç¯å¢ƒæµ‹è¯•è´ŸåŠ¨ä½œ
    env.reset()
    print(f"\nå®éªŒ2: ä½¿ç”¨åˆ¹è½¦åŠ¨ä½œ [0, -1]")
    initial_pos = [env.agent.position[0], env.agent.position[1]]
    
    for step in range(3):
        obs, reward, done, info = env.step([0, -1])  # åˆ¹è½¦åŠ¨ä½œ
        new_pos = [env.agent.position[0], env.agent.position[1]]
        distance = ((new_pos[0] - initial_pos[0])**2 + (new_pos[1] - initial_pos[1])**2)**0.5
        print(f"  æ­¥éª¤ {step+1}: åŠ¨ä½œ=[0,-1], ç§»åŠ¨={distance:.3f}m, é€Ÿåº¦={env.agent.speed:.2f}m/s")
    
    # é‡ç½®ç¯å¢ƒæµ‹è¯•åŠ é€ŸåŠ¨ä½œ
    env.reset()
    print(f"\nå®éªŒ3: ä½¿ç”¨åŠ é€ŸåŠ¨ä½œ [0, 1]")
    initial_pos = [env.agent.position[0], env.agent.position[1]]
    
    for step in range(3):
        obs, reward, done, info = env.step([0, 1])  # åŠ é€ŸåŠ¨ä½œ
        new_pos = [env.agent.position[0], env.agent.position[1]]
        distance = ((new_pos[0] - initial_pos[0])**2 + (new_pos[1] - initial_pos[1])**2)**0.5
        print(f"  æ­¥éª¤ {step+1}: åŠ¨ä½œ=[0,1], ç§»åŠ¨={distance:.3f}m, é€Ÿåº¦={env.agent.speed:.2f}m/s")
    
    env.close()

if __name__ == "__main__":
    verify_ppo_effect()
