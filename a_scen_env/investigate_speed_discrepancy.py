#!/usr/bin/env python3

import sys
import os
import numpy as np
sys.path.append('.')

from trajectory_replay import TrajectoryReplayEnv
from trajectory_loader import load_trajectory

def investigate_speed_discrepancy():
    print("ğŸ” æ·±åº¦åˆ†æï¼šä¸»è½¦é€Ÿåº¦æ˜¾ç¤ºvså®é™…ç§»åŠ¨çš„å·®å¼‚")
    print("="*70)
    
    # åŠ è½½æ•°æ®
    csv_path = "scenario_vehicles_8_0_1_2_3_4_5_6_7_test3_20250304_162012_row070_filtered.csv"
    traj_data = load_trajectory(csv_path=csv_path, normalize_position=False, max_duration=3, 
                               use_original_position=False, translate_to_origin=True, target_fps=50.0)
    
    # åˆ›å»ºç¯å¢ƒ
    env = TrajectoryReplayEnv(traj_data, config=dict(use_render=False))
    env.reset()
    
    print(f"\nğŸ“Š åˆå§‹çŠ¶æ€è¯¦ç»†åˆ†æ:")
    print(f"  ä¸»è½¦ä½ç½®: ({env.agent.position[0]:.6f}, {env.agent.position[1]:.6f})")
    print(f"  ä¸»è½¦é€Ÿåº¦æ˜¾ç¤º: {env.agent.speed:.6f} m/s")
    print(f"  ä¸»è½¦é€Ÿåº¦å‘é‡: ({env.agent.velocity[0]:.6f}, {env.agent.velocity[1]:.6f})")
    
    # æ£€æŸ¥ç‰©ç†å¼•æ“çš„å…·ä½“æ•°å€¼
    if hasattr(env.agent, '_body') and env.agent._body:
        body = env.agent._body
        linear_vel = body.getLinearVelocity()
        print(f"  ç‰©ç†å¼•æ“çº¿æ€§é€Ÿåº¦: ({linear_vel[0]:.6f}, {linear_vel[1]:.6f}, {linear_vel[2]:.6f})")
        print(f"  ç‰©ç†å¼•æ“é€Ÿåº¦å¤§å°: {(linear_vel[0]**2 + linear_vel[1]**2)**0.5:.6f}")
    
    dt = env.physics_world_step_size
    print(f"  ç‰©ç†æ—¶é—´æ­¥é•¿: {dt:.6f} ç§’")
    
    print(f"\nğŸƒ é€æ­¥è¿åŠ¨åˆ†æ:")
    initial_pos = [env.agent.position[0], env.agent.position[1]]
    
    for step in range(3):
        print(f"\n  --- æ­¥éª¤ {step+1} ---")
        print(f"  æ­¥éª¤å‰ä½ç½®: ({env.agent.position[0]:.6f}, {env.agent.position[1]:.6f})")
        print(f"  æ­¥éª¤å‰é€Ÿåº¦æ˜¾ç¤º: {env.agent.speed:.6f} m/s")
        print(f"  æ­¥éª¤å‰é€Ÿåº¦å‘é‡: ({env.agent.velocity[0]:.6f}, {env.agent.velocity[1]:.6f})")
        
        # æ‰§è¡Œä¸€æ­¥
        obs, reward, done, info = env.step([0, 0])  # é›¶åŠ¨ä½œ
        
        print(f"  æ­¥éª¤åä½ç½®: ({env.agent.position[0]:.6f}, {env.agent.position[1]:.6f})")
        print(f"  æ­¥éª¤åé€Ÿåº¦æ˜¾ç¤º: {env.agent.speed:.6f} m/s")
        print(f"  æ­¥éª¤åé€Ÿåº¦å‘é‡: ({env.agent.velocity[0]:.6f}, {env.agent.velocity[1]:.6f})")
        
        # è®¡ç®—ä½ç½®å˜åŒ–
        new_pos = [env.agent.position[0], env.agent.position[1]]
        dx = new_pos[0] - initial_pos[0]
        dy = new_pos[1] - initial_pos[1]
        step_distance = (dx**2 + dy**2)**0.5
        step_speed = step_distance / dt
        
        print(f"  ä½ç½®å˜åŒ–: dx={dx:.6f}, dy={dy:.6f}")
        print(f"  æ­¤æ­¥ç§»åŠ¨è·ç¦»: {step_distance:.6f} m")
        print(f"  æ­¤æ­¥è®¡ç®—é€Ÿåº¦: {step_speed:.6f} m/s")
        print(f"  é€Ÿåº¦å·®å¼‚å€æ•°: {step_speed / env.agent.speed:.3f}x" if env.agent.speed > 0 else "  æ— æ³•è®¡ç®—å€æ•°")
        
        # ç†è®ºvså®é™…
        theoretical_distance = env.agent.speed * dt
        print(f"  ç†è®ºç§»åŠ¨è·ç¦»: {theoretical_distance:.6f} m")
        print(f"  å®é™…/ç†è®ºæ¯”ç‡: {step_distance / theoretical_distance:.3f}" if theoretical_distance > 0 else "  æ— æ³•è®¡ç®—æ¯”ç‡")
    
    print(f"\nğŸ”¬ é—®é¢˜æ·±åº¦åˆ†æ:")
    
    # æ£€æŸ¥MetaDriveçš„é€Ÿåº¦è®¡ç®—æ–¹æ³•
    print(f"1ï¸âƒ£ MetaDriveé€Ÿåº¦è®¡ç®—æ–¹æ³•:")
    if hasattr(env.agent, '_body') and env.agent._body:
        body = env.agent._body
        linear_vel = body.getLinearVelocity()
        computed_speed = (linear_vel[0]**2 + linear_vel[1]**2)**0.5
        print(f"   ç‰©ç†å¼•æ“é€Ÿåº¦å‘é‡: ({linear_vel[0]:.3f}, {linear_vel[1]:.3f})")
        print(f"   è®¡ç®—å¾—å‡ºçš„é€Ÿåº¦: {computed_speed:.3f} m/s")
        print(f"   agent.speedå±æ€§: {env.agent.speed:.3f} m/s")
        print(f"   ä¸¤è€…æ˜¯å¦ä¸€è‡´: {'âœ… æ˜¯' if abs(computed_speed - env.agent.speed) < 0.001 else 'âŒ å¦'}")
    
    print(f"\n2ï¸âƒ£ å¯èƒ½çš„åŸå› åˆ†æ:")
    print(f"   ç†è®ºA: æ—¶é—´æ­¥é•¿ä¸ä¸€è‡´ - dt={dt:.6f}s")
    print(f"   ç†è®ºB: PPOåŠ¨ä½œå åŠ æ•ˆåº”")
    print(f"   ç†è®ºC: ç‰©ç†å¼•æ“å†…éƒ¨ç¼©æ”¾")
    print(f"   ç†è®ºD: MetaDriveåæ ‡ç³»ç»Ÿé—®é¢˜")
    
    print(f"\n3ï¸âƒ£ å…³é”®å‘ç°:")
    total_distance = ((env.agent.position[0] - 200)**2 + (env.agent.position[1] - 7)**2)**0.5
    total_time = 3 * dt
    average_speed = total_distance / total_time
    print(f"   3æ­¥æ€»ç§»åŠ¨è·ç¦»: {total_distance:.3f} m")
    print(f"   3æ­¥æ€»æ—¶é—´: {total_time:.6f} s")
    print(f"   å¹³å‡å®é™…é€Ÿåº¦: {average_speed:.3f} m/s")
    print(f"   æ˜¾ç¤ºé€Ÿåº¦å¹³å‡: ~26.6 m/s")
    print(f"   å®é™…/æ˜¾ç¤ºæ¯”ç‡: {average_speed / 26.6:.3f}x")
    
    print(f"\nğŸ’¡ å¯èƒ½çš„è§£é‡Š:")
    print(f"   1. PPOæ§åˆ¶å™¨å¯èƒ½åœ¨æ¯ä¸ªæ—¶é—´æ­¥å†…å¤šæ¬¡æ›´æ–°ç‰©ç†çŠ¶æ€")
    print(f"   2. MetaDriveçš„decision_repeatå¯èƒ½>1ï¼Œå¯¼è‡´å®é™…ç‰©ç†æ­¥æ•°æ›´å¤š")
    print(f"   3. ç‰©ç†å¼•æ“çš„å†…éƒ¨æ—¶é—´æ­¥å¯èƒ½ä¸æ˜¾ç¤ºçš„ä¸ä¸€è‡´")
    print(f"   4. speedå±æ€§å¯èƒ½æ˜¯å¹³æ»‘åŒ–æˆ–æ»åçš„æ˜¾ç¤ºå€¼")
    
    # æ£€æŸ¥MetaDriveçš„é…ç½®
    print(f"\nâš™ï¸ MetaDriveé…ç½®æ£€æŸ¥:")
    try:
        config = env.engine.global_config
        print(f"   decision_repeat: {config.get('decision_repeat', 'æœªè®¾ç½®')}")
        print(f"   physics_world_step_size: {config.get('physics_world_step_size', 'æœªè®¾ç½®')}")
        print(f"   å…¶ä»–æ—¶é—´ç›¸å…³é…ç½®: {[k for k in config.keys() if 'time' in k.lower() or 'step' in k.lower() or 'dt' in k.lower()]}")
    except:
        print(f"   æ— æ³•è·å–é…ç½®ä¿¡æ¯")
    
    env.close()

if __name__ == "__main__":
    investigate_speed_discrepancy()
