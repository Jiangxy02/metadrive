#!/usr/bin/env python3
"""
è®¤çŸ¥æ¨¡å—å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•è„šæœ¬
è¿è¡ŒçŸ­æœŸä»¿çœŸå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
"""

import sys
import os
import numpy as np

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(os.path.dirname(current_dir))
cognitive_module_dir = os.path.join(parent_dir, 'cognitive_module')
if cognitive_module_dir not in sys.path:
    sys.path.insert(0, cognitive_module_dir)

from trajectory_replay_cognitive import TrajectoryReplayEnvCognitive
from trajectory_loader import load_trajectory

def test_cognitive_visualization():
    """æµ‹è¯•è®¤çŸ¥å¯è§†åŒ–åŠŸèƒ½"""
    print("=== è®¤çŸ¥æ¨¡å—å¯è§†åŒ–åŠŸèƒ½æµ‹è¯• ===\n")
    
    # æµ‹è¯•CSVè·¯å¾„
    csv_path = "/home/jxy/æ¡Œé¢/1_Project/20250705_computational_cognitive_modeling/computational_cognitive_modeling/metadrive/a_scen_env/scenario_vehicles_9_0_1_2_3_4_5_6_7_8_test3_20250304_150943_row001_filtered.csv"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(csv_path):
        print(f"âŒ è½¨è¿¹æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return False
    
    try:
        # åŠ è½½è½¨è¿¹æ•°æ®
        print("ğŸ“ åŠ è½½è½¨è¿¹æ•°æ®...")
        traj_data = load_trajectory(
            csv_path=csv_path,
            normalize_position=False,
            max_duration=30,  # é™åˆ¶ä¸º30ç§’æµ‹è¯•
            use_original_position=False,
            translate_to_origin=True,
            target_fps=50.0,
            use_original_timestamps=True
        )
        
        print(f"âœ… åŠ è½½äº† {len(traj_data)} è¾†è½¦çš„è½¨è¿¹æ•°æ®")
        
        # è®¤çŸ¥æ¨¡å—é…ç½®
        COGNITIVE_CONFIG = {
            'perception': {
                'enable': True,
                'sigma': 0.5,
                'enable_kalman': True,
                'process_noise': 0.1,
                'dt': 0.02
            },
            'cognitive_bias': {
                'enable': False,  # æš‚æœªå®ç°
            },
            'delay': {
                'enable': True,
                'delay_steps': 3,
                'enable_smoothing': True,
                'smoothing_factor': 0.4
            }
        }
        
        # åˆ›å»ºè®¤çŸ¥ç¯å¢ƒ
        print("ğŸ—ï¸ åˆå§‹åŒ–è®¤çŸ¥ç¯å¢ƒ...")
        env = TrajectoryReplayEnvCognitive(
            traj_data,
            config={
                'use_render': False,  # å…³é—­æ¸²æŸ“åŠ å¿«æµ‹è¯•
                'manual_control': False,
                'enable_background_vehicles': True,
                'background_vehicle_update_mode': "position",
                'enable_realtime': False,  # å…³é—­å®æ—¶æ¨¡å¼
                'target_fps': 50.0,
                
                # å¯ç”¨è®¤çŸ¥æ¨¡å—
                'enable_cognitive_modules': True,
                'cognitive_config': COGNITIVE_CONFIG,
                
                # å¯ç”¨å¯è§†åŒ–ï¼ˆè¾“å‡ºç›®å½•å°†è‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³æ–‡ä»¶å¤¹ï¼‰
                'enable_visualization': True
            }
        )
        
        print("âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
        
        # é‡ç½®ç¯å¢ƒ
        obs = env.reset()
        print("ğŸ”„ ç¯å¢ƒå·²é‡ç½®")
        
        print(f"ğŸ“ ä¸»è½¦ä½ç½®: {env.agent.position}")
        print(f"ğŸ® æ§åˆ¶æ¨¡å¼: PPO Expert (é»˜è®¤)")
        
        # è¿è¡Œä»¿çœŸ
        print("\nğŸš€ å¼€å§‹ä»¿çœŸæµ‹è¯•...")
        max_steps = 200  # é™åˆ¶æ­¥æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        
        for i in range(max_steps):
            # ä½¿ç”¨ç®€å•çš„å‰è¿›åŠ¨ä½œè¿›è¡Œæµ‹è¯•
            action = np.array([0.0, 0.3])  # ç›´è¡Œï¼Œè½»æ²¹é—¨
            
            obs, reward, done, info = env.step(action)
            
            # æ¯50æ­¥è¾“å‡ºä¸€æ¬¡çŠ¶æ€
            if i % 50 == 0:
                mode = info.get('Control Mode', 'unknown')
                cognitive_active = info.get('cognitive_modules_active', False)
                speed = env.agent.speed
                print(f"  Step {i}: æ§åˆ¶æ¨¡å¼={mode}, è®¤çŸ¥æ¨¡å—={'æ¿€æ´»' if cognitive_active else 'æœªæ¿€æ´»'}, é€Ÿåº¦={speed:.2f} m/s")
            
            if done:
                print(f"  ä»¿çœŸåœ¨ç¬¬{i}æ­¥ç»“æŸ")
                break
        
        print(f"âœ… ä»¿çœŸå®Œæˆï¼Œæ€»è®¡ {min(i+1, max_steps)} æ­¥")
        
        # å…³é—­ç¯å¢ƒï¼ˆè¿™ä¼šè§¦å‘å›¾è¡¨ç”Ÿæˆï¼‰
        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        env.close()
        
        # æ£€æŸ¥ç”Ÿæˆçš„å›¾è¡¨
        if hasattr(env, 'visualization_output_dir') and os.path.exists(env.visualization_output_dir):
            fig_dir = env.visualization_output_dir
            files = [f for f in os.listdir(fig_dir) if f.endswith('.png')]
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(files)} ä¸ªå›¾è¡¨æ–‡ä»¶:")
            for file in sorted(files):
                print(f"  - {file}")
            print(f"ğŸ“ å›¾è¡¨ä¿å­˜ä½ç½®: {fig_dir}")
        else:
            print("âŒ å›¾è¡¨ç›®å½•ä¸å­˜åœ¨")
            
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_cognitive_visualization()
    if success:
        print("\nğŸ‰ è®¤çŸ¥æ¨¡å—å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•æˆåŠŸ!")
        print("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨: fig_cog ç›®å½•")
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    print("\n=== æµ‹è¯•å®Œæˆ ===") 