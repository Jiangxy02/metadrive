"""
è½¨è¿¹é‡æ”¾ç¯å¢ƒ - è®¤çŸ¥æ¨¡å—é›†æˆç‰ˆæœ¬
åŸºäºtrajectory_replay.pyï¼Œé›†æˆè®¤çŸ¥æ¨¡å—å®ç°äººç±»è®¤çŸ¥å»ºæ¨¡
æ„ŸçŸ¥è¯¯å·®å’Œæ‰§è¡Œå»¶è¿Ÿä»…åœ¨PPOæ¨¡å¼ä¸‹ç”Ÿæ•ˆ
"""

import pandas as pd
import numpy as np
from metadrive.envs import MetaDriveEnv
from metadrive.component.vehicle.vehicle_type import DefaultVehicle
from metadrive.engine.engine_utils import get_global_config
from metadrive.constants import HELP_MESSAGE
import sys
import os

# æ·»åŠ è®¤çŸ¥æ¨¡å—è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(os.path.dirname(current_dir))
cognitive_module_dir = os.path.join(parent_dir, 'cognitive_module')
if cognitive_module_dir not in sys.path:
    sys.path.insert(0, cognitive_module_dir)

# å¯¼å…¥è®¤çŸ¥æ¨¡å—
from cognitive_wrappers import PerceptionWrapper, CognitiveBiasWrapper, DelayWrapper
from cognitive_perception_module import CognitivePerceptionModule
from cognitive_bias_module import CognitiveBiasModule  # æ–°å¢ï¼šå¯¼å…¥è®¤çŸ¥åå·®æ¨¡å—

# å¯¼å…¥å¯è§†åŒ–æ¨¡å—
from cognitive_visualization import CognitiveDataRecorder, CognitiveVisualizer

# å¯¼å…¥åŸæœ‰æ¨¡å—
from control_mode_manager import ControlModeManager
from trajectory_loader import TrajectoryLoader, load_trajectory
from metadrive.component.navigation_module.node_network_navigation import NodeNetworkNavigation
from observation_recorder import ObservationRecorder


class CognitiveDelayModule:
    """
    è®¤çŸ¥å»¶è¿Ÿæ¨¡å— - ç‹¬ç«‹å®ç°ï¼Œä¸ä¾èµ–gymç¯å¢ƒ
    ä»…åœ¨PPOæ¨¡å¼ä¸‹åº”ç”¨æ‰§è¡Œå»¶è¿Ÿ
    """
    def __init__(self, delay_steps=2, enable_smoothing=True, smoothing_factor=0.3):
        self.delay_steps = delay_steps
        self.enable_smoothing = enable_smoothing
        self.smoothing_factor = smoothing_factor
        
        from collections import deque
        self.buffer = deque(maxlen=delay_steps + 1)
        self.previous_action = np.array([0.0, 0.0])
        
    def process_action(self, action, is_ppo_mode=False):
        """
        å¤„ç†åŠ¨ä½œï¼Œä»…åœ¨PPOæ¨¡å¼ä¸‹åº”ç”¨å»¶è¿Ÿ
        
        Args:
            action: åŸå§‹åŠ¨ä½œ
            is_ppo_mode: æ˜¯å¦ä¸ºPPOä¸“å®¶æ¨¡å¼
            
        Returns:
            å¤„ç†åçš„åŠ¨ä½œ
        """
        if not is_ppo_mode:
            return action  # éPPOæ¨¡å¼ç›´æ¥è¿”å›åŸå§‹åŠ¨ä½œ
            
        # ç¡®ä¿actionæ˜¯numpyæ•°ç»„
        action = np.array(action, dtype=np.float32)
        
        # è®°å½•åŸå§‹å‘½ä»¤ä¾›å¯è§†åŒ–ä½¿ç”¨
        self._last_commanded_action = action.copy()

        # åŠ¨ä½œå¹³æ»‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_smoothing:
            smoothed_action = (
                self.smoothing_factor * action +
                (1 - self.smoothing_factor) * self.previous_action
            )
            self.previous_action = smoothed_action.copy()
        else:
            smoothed_action = action
        
        # æ·»åŠ åˆ°å»¶è¿Ÿç¼“å†²åŒº
        self.buffer.append(smoothed_action.copy())
        
        # è·å–å»¶è¿Ÿåçš„åŠ¨ä½œ
        if len(self.buffer) <= self.delay_steps:
            # åˆå§‹å‡ æ­¥è¿”å›é›¶åŠ¨ä½œ
            delayed_action = np.array([0.0, 0.0])
        else:
            # è¿”å›å»¶è¿Ÿçš„åŠ¨ä½œ
            delayed_action = self.buffer[0]
        
        return delayed_action
    
    def reset(self):
        """é‡ç½®å»¶è¿Ÿæ¨¡å—"""
        self.buffer.clear()
        self.previous_action = np.array([0.0, 0.0])


class TrajectoryReplayEnvCognitive(MetaDriveEnv):
    """
    è½¨è¿¹é‡æ”¾ç¯å¢ƒ - è®¤çŸ¥æ¨¡å—é›†æˆç‰ˆæœ¬
    
    åœ¨åŸæœ‰åŠŸèƒ½åŸºç¡€ä¸Šï¼Œé›†æˆè®¤çŸ¥å»ºæ¨¡æ¨¡å—ï¼š
    - PerceptionModule: æ„ŸçŸ¥è¯¯å·®å’Œå¡å°”æ›¼æ»¤æ³¢ï¼ˆä»…PPOæ¨¡å¼ï¼‰
    - CognitiveBiasModule: TTAè®¤çŸ¥åå·®ï¼ˆæ‰€æœ‰æ¨¡å¼ï¼‰
    - DelayModule: æ‰§è¡Œå»¶è¿Ÿï¼ˆä»…PPOæ¨¡å¼ï¼‰
    """
    
    def __init__(self, trajectory_dict, config=None):
        # å¤„ç†é…ç½®å‚æ•°
        user_config = config.copy() if config else {}
        
        # è®¤çŸ¥æ¨¡å—é…ç½®
        self.enable_cognitive_modules = user_config.pop("enable_cognitive_modules", False)
        self.cognitive_config = user_config.pop("cognitive_config", {})
        
        # å¯è§†åŒ–é…ç½®
        self.enable_visualization = user_config.pop("enable_visualization", True)
        
        # åˆ›å»ºåŸºäºæ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        base_dir = "/home/jxy/æ¡Œé¢/1_Project/20250705_computational_cognitive_modeling/computational_cognitive_modeling/metadrive/a_scen_env/fig_cog"
        self.visualization_output_dir = f"{base_dir}/cognitive_analysis_{timestamp}"
        
        # åˆå§‹åŒ–è®¤çŸ¥æ¨¡å—ï¼ˆåœ¨super().__init__ä¹‹å‰ï¼‰
        self.perception_module = None
        self.cognitive_bias_module = None  # æ–°å¢ï¼šåˆå§‹åŒ–è®¤çŸ¥åå·®æ¨¡å—
        self.delay_module = None
        
        # åˆå§‹åŒ–å¯è§†åŒ–æ¨¡å—
        self.data_recorder = None
        self.visualizer = None
        
        if self.enable_cognitive_modules:
            self._initialize_cognitive_modules()
            
        if self.enable_visualization:
            self._initialize_visualization()
            
        # ä¿å­˜åŸå§‹çš„trajectory_dictç”¨äºèƒŒæ™¯è½¦
        self.enable_background_vehicles = user_config.get("enable_background_vehicles", False)
        
        # å¤åˆ¶trajectory_dicté¿å…ä¿®æ”¹åŸæ•°æ®
        original_trajectory_dict = trajectory_dict.copy()
        
        # å°†è½¦è¾†-1è®¾ç½®ä¸ºä¸»è½¦
        self.main_vehicle_trajectory = None
        if -1 in original_trajectory_dict:
            self.main_vehicle_trajectory = original_trajectory_dict.pop(-1)
            print(f"Vehicle -1 will be used as the main car (agent)")
        else:
            print("Warning: Vehicle -1 not found in trajectory data")
        
        # æ ¹æ®enable_background_vehicleså‚æ•°å†³å®šæ˜¯å¦ä¿ç•™èƒŒæ™¯è½¦æ•°æ®
        if self.enable_background_vehicles:
            self.trajectory_dict = original_trajectory_dict
            print(f"Loaded {len(self.trajectory_dict)} background vehicles from CSV")
        else:
            self.trajectory_dict = {}
            print("âš ï¸  Background vehicles disabled")
            
        # è®¡ç®—æœ€å¤§æ­¥æ•°
        if self.trajectory_dict:
            self.max_step = max(len(traj) for traj in self.trajectory_dict.values())
        elif self.main_vehicle_trajectory:
            self.max_step = len(self.main_vehicle_trajectory)
        else:
            self.max_step = 1000
            
        self._step_count = 0
        self._simulation_time = 0.0
        self._trajectory_start_time = None
        
        # å®æ—¶æ—¶é—´è·Ÿè¸ª
        import time
        self._real_start_time = None
        self._real_time_module = time
        
        # è®¾ç½®é»˜è®¤é…ç½®
        default_config = {
            "use_render": True,
            "map": "S"*8,
            "manual_control": True,
            "controller": "keyboard",
            "start_seed": 0,
            "map_region_size": 2048,
            "drivable_area_extension": 50,
            "horizon": 10000,
            "traffic_density": 0.0,
            "accident_prob": 0.0,
            "static_traffic_object": False,
            "vehicle_config": {
                "show_navi_mark": True,
                "show_dest_mark": True,
                "show_line_to_dest": True,
                "show_line_to_navi_mark": True,
                "show_navigation_arrow": True,
                "navigation_module": NodeNetworkNavigation,
                "destination": None,
                "spawn_lane_index": None,
            }
        }
        
        # å¤„ç†å…¶ä»–ç”¨æˆ·é…ç½®
        user_config.pop("enable_background_vehicles", None)
        
        self.enable_realtime = user_config.pop("enable_realtime", True)
        self.target_fps = user_config.pop("target_fps", 50.0)
        self._last_step_time = None
        
        self.end_on_crash = user_config.pop("end_on_crash", False)
        self.end_on_out_of_road = user_config.pop("end_on_out_of_road", False)
        self.end_on_arrive_dest = user_config.pop("end_on_arrive_dest", False)
        self.end_on_horizon = user_config.pop("end_on_horizon", False)
        
        self.background_vehicle_update_mode = user_config.pop("background_vehicle_update_mode", "position")
        self.disable_ppo_expert = user_config.pop("disable_ppo_expert", False)
        
        # è§‚æµ‹è®°å½•å™¨é…ç½®
        self.enable_observation_recording = user_config.pop("enable_observation_recording", False)
        self.observation_recorder = None
        if self.enable_observation_recording:
            session_name = user_config.pop("recording_session_name", None)
            output_dir = user_config.pop("recording_output_dir", "observation_logs")
            self.observation_recorder = ObservationRecorder(output_dir=output_dir, session_name=session_name)
            print("âœ… è§‚æµ‹è®°å½•å™¨å·²å¯ç”¨")
        
        if user_config:
            default_config.update(user_config)
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(default_config)
        
        # è·å–ä»¿çœŸæ—¶é—´æ­¥é•¿
        try:
            self.physics_world_step_size = self.engine.physics_world.static_world.getPhysicsWorldStepSize()
            print(f"MetaDrive physics step size: {self.physics_world_step_size:.6f} seconds")
        except AttributeError:
            self.physics_world_step_size = 0.02
            print(f"Using default physics step size: {self.physics_world_step_size:.6f} seconds")
        
        # åˆå§‹åŒ–æ§åˆ¶æ¨¡å¼ç®¡ç†å™¨
        self.control_manager = ControlModeManager(
            engine=self.engine,
            main_vehicle_trajectory=self.main_vehicle_trajectory
        )
        
        # èƒŒæ™¯è½¦ç¼“å­˜
        self.ghost_vehicles = {}
        
        # é‡å†™max_step
        self.max_step = 10000
        
        print("\n=== è®¤çŸ¥æ¨¡å—çŠ¶æ€ ===")
        if self.enable_cognitive_modules:
            print("âœ… è®¤çŸ¥æ¨¡å—å·²å¯ç”¨")
            if self.perception_module:
                print(f"  - æ„ŸçŸ¥æ¨¡å—: sigma={self.perception_module.sigma}, kalman={self.perception_module.enable_kalman}")
            if self.delay_module:
                print(f"  - å»¶è¿Ÿæ¨¡å—: delay_steps={self.delay_module.delay_steps}, smoothing={self.delay_module.enable_smoothing}")
            print("  - è®¤çŸ¥æ¨¡å—ä»…åœ¨PPOä¸“å®¶æ¨¡å¼ä¸‹ç”Ÿæ•ˆ")
        else:
            print("âŒ è®¤çŸ¥æ¨¡å—æœªå¯ç”¨")
        print("=" * 30 + "\n")
    
    def _initialize_cognitive_modules(self):
        """åˆå§‹åŒ–è®¤çŸ¥æ¨¡å—"""
        print("æ­£åœ¨åˆå§‹åŒ–è®¤çŸ¥æ¨¡å—...")
        
        # æ„ŸçŸ¥æ¨¡å—é…ç½® - ä½¿ç”¨æ–°çš„é›·è¾¾å™ªå£°æ³¨å…¥æ¨¡å—
        perception_config = self.cognitive_config.get('perception', {})
        
        # è½¬æ¢é…ç½®æ ¼å¼ä»¥é€‚é…æ–°çš„å™ªå£°æ¨¡å—
        noise_config = {
            'sigma0': perception_config.get('sigma', 0.5),  # åŸºç¡€å™ªå£°
            'k': perception_config.get('k', 0.02),          # è·ç¦»ç›¸å…³ç³»æ•°
            
            # æ¼æ£€é…ç½®
            'p_miss0': perception_config.get('p_miss0', 0.01),  # åŸºç¡€æ¼æ£€æ¦‚ç‡
            'far_distance': perception_config.get('far_distance', 50.0),
            
            # è¯¯æ£€é…ç½®ï¼ˆä¿å®ˆé»˜è®¤å€¼ï¼‰
            'p_false': perception_config.get('p_false', 0.0001), # è¯¯æ£€æ¦‚ç‡ï¼ˆå¤§å¹…é™ä½ï¼‰
            'near_min': perception_config.get('near_min', 1.0),  # è¯¯æ£€æœ€è¿‘è·ç¦»
            'near_max': perception_config.get('near_max', 5.0),  # è¯¯æ£€æœ€è¿œè·ç¦»
            
            # è§’åº¦æŠ–åŠ¨
            'angle_jitter_steps': perception_config.get('angle_jitter_steps', 1),
            
            # æ—¶é—´ç›¸å…³æ€§é…ç½®
            'use_ar1': perception_config.get('use_ar1', True),   # å¯ç”¨AR(1)
            'rho': perception_config.get('rho', 0.8),            # AR(1)ç³»æ•°
            'use_lowpass': perception_config.get('use_lowpass', False),
            'alpha': perception_config.get('alpha', 0.7),
            
            # KFé…ç½®
            'use_kf': perception_config.get('use_kf', True),
            'kf_dt': perception_config.get('kf_dt', 0.1),
            'kf_q': perception_config.get('kf_q', 0.5),
            'kf_sigma_a': perception_config.get('kf_sigma_a', 3.0),
            'kf_q_scale': perception_config.get('kf_q_scale', 100.0),
            'kf_r_floor': perception_config.get('kf_r_floor', 1e-4),
            'kf_init_std_pos': perception_config.get('kf_init_std_pos', 5.0),
            'kf_init_std_vel': perception_config.get('kf_init_std_vel', 10.0),
        }
        
        self.perception_module = CognitivePerceptionModule(noise_config)
        print("  âœ… æ„ŸçŸ¥æ¨¡å—å·²åˆå§‹åŒ–ï¼ˆé›·è¾¾å™ªå£°æ³¨å…¥å™¨ï¼‰")
        
        # å»¶è¿Ÿæ¨¡å—é…ç½®
        delay_config = self.cognitive_config.get('delay', {})
        if delay_config.get('enable', False):
            self.delay_module = CognitiveDelayModule(
                delay_steps=delay_config.get('delay_steps', 2),
                enable_smoothing=delay_config.get('enable_smoothing', True),
                smoothing_factor=delay_config.get('smoothing_factor', 0.3)
            )
            print("  âœ… å»¶è¿Ÿæ¨¡å—å·²åˆå§‹åŒ–")
        
        # è®¤çŸ¥åå·®æ¨¡å—é…ç½®ï¼ˆæ–°å¢ï¼‰
        cognitive_bias_config = self.cognitive_config.get('cognitive_bias', {})
        if cognitive_bias_config.get('enable', False):
            # åˆ›å»ºè®¤çŸ¥åå·®æ¨¡å—
            bias_config = {
                'inverse_tta_coef': cognitive_bias_config.get('inverse_tta_coef', 1.0),
                'tta_threshold': cognitive_bias_config.get('tta_threshold', 1.0),
                'adaptive_bias': cognitive_bias_config.get('adaptive_bias', True),
                'adaptation_rate': cognitive_bias_config.get('adaptation_rate', 0.01),
                'min_adaptive_factor': cognitive_bias_config.get('min_adaptive_factor', 0.5),
                'max_adaptive_factor': cognitive_bias_config.get('max_adaptive_factor', 2.0),
                'history_length': cognitive_bias_config.get('history_length', 100),
                'verbose': cognitive_bias_config.get('verbose', False),
                
                # è§†è§‰åŒæ¶å‚æ•°
                'visual_detection_distance': cognitive_bias_config.get('visual_detection_distance', 50.0),
                'visual_detection_angle': cognitive_bias_config.get('visual_detection_angle', 30.0),
                'visual_aversion_strength': cognitive_bias_config.get('visual_aversion_strength', 0.5)
            }
            self.cognitive_bias_module = CognitiveBiasModule(bias_config)
            print("  âœ… è®¤çŸ¥åå·®æ¨¡å—å·²åˆå§‹åŒ–ï¼ˆTTAé£é™©åŒæ¶ï¼‰")

    def _initialize_visualization(self):
        """åˆå§‹åŒ–å¯è§†åŒ–æ¨¡å—"""
        print("æ­£åœ¨åˆå§‹åŒ–å¯è§†åŒ–æ¨¡å—...")
        
        try:
            self.data_recorder = CognitiveDataRecorder()
            self.visualizer = CognitiveVisualizer(output_dir=self.visualization_output_dir)
            print(f"âœ… å¯è§†åŒ–æ¨¡å—å·²åˆå§‹åŒ–ï¼Œè¾“å‡ºç›®å½•: {self.visualization_output_dir}")
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
            self.enable_visualization = False
    
    def reset(self):
        """é‡ç½®ç¯å¢ƒï¼ŒåŒ…æ‹¬è®¤çŸ¥æ¨¡å—"""
        # æ¸…ç†èƒŒæ™¯è½¦
        self._cleanup_ghost_vehicles()
        
        # è°ƒç”¨çˆ¶ç±»reset
        reset_result = super().reset()
        
        # å¤„ç†resetè¿”å›å€¼ï¼ˆå¯èƒ½æ˜¯(obs, info)å…ƒç»„æˆ–å•ç‹¬çš„obsï¼‰
        if isinstance(reset_result, tuple) and len(reset_result) == 2:
            obs, reset_info = reset_result
        else:
            obs = reset_result
            reset_info = {}
        
        # é‡ç½®è®¡æ•°å™¨å’Œæ—¶é—´
        self._step_count = 0
        self._simulation_time = 0.0
        self._real_start_time = self._real_time_module.time()
        self._last_step_time = self._real_start_time
        self.ghost_vehicles = {}
        
        # åˆå§‹åŒ–è½¨è¿¹èµ·å§‹æ—¶é—´
        if self.main_vehicle_trajectory and "timestamp" in self.main_vehicle_trajectory[0]:
            self._trajectory_start_time = self.main_vehicle_trajectory[0]["timestamp"]
        else:
            self._trajectory_start_time = 0.0
        
        # è®¾ç½®æ§åˆ¶ç®¡ç†å™¨
        self.control_manager.set_agent(self.agent)
        self.control_manager.reset_modes()
        self.control_manager.bind_hotkeys()
        self.control_manager.initialize_policies()
        
        # ===== æ–°å¢ï¼šè®¾ç½®è‡ªå®šä¹‰ç›®æ ‡ç‚¹ =====
        self._set_custom_destination()
        
        # ===== æ–°å¢ï¼šè°ƒè¯•å¯¼èˆªä¿¡æ¯ =====
        self._debug_navigation_info()
        
        # è®¾ç½®ä¸»è½¦åˆå§‹çŠ¶æ€
        if self.main_vehicle_trajectory and len(self.main_vehicle_trajectory) > 0:
            initial_state = self.main_vehicle_trajectory[0]
            self.agent.set_position([initial_state["x"], initial_state["y"]])
            self.agent.set_heading_theta(initial_state["heading"])
            direction = [np.cos(initial_state["heading"]), np.sin(initial_state["heading"])]
            self.agent.set_velocity(direction, initial_state["speed"])
            print(f"Main car initialized at original position: ({initial_state['x']:.1f}, {initial_state['y']:.1f})")
            print(f"Initial heading: {initial_state['heading']:.2f} rad, speed: {initial_state['speed']:.1f} m/s")

            # ===== æ–°å¢ï¼šåœ¨ä¸»è½¦ä½ç½®è®¾ç½®åä¿®å¤è½¦é“æ£€æµ‹é—®é¢˜ =====
            self._fix_lane_detection()
        
        # é‡ç½®è®¤çŸ¥æ¨¡å—
        if self.enable_cognitive_modules:
            # é™„åŠ å™ªå£°é›·è¾¾åˆ°ç¯å¢ƒï¼ˆåœ¨ç¯å¢ƒå®Œå…¨åˆå§‹åŒ–åï¼‰
            if self.perception_module:
                success = self.perception_module.attach_to_env(self)
                if success:
                    print("  âœ… å™ªå£°é›·è¾¾å·²é™„åŠ åˆ°ç¯å¢ƒ")
                else:
                    print("  âš ï¸ å™ªå£°é›·è¾¾é™„åŠ å¤±è´¥ï¼Œå°†è·³è¿‡é›·è¾¾å™ªå£°æ³¨å…¥")
                self.perception_module.reset()
            
            # é™„åŠ å’Œé‡ç½®è®¤çŸ¥åå·®æ¨¡å—
            if self.cognitive_bias_module:
                success = self.cognitive_bias_module.attach_to_env(self)
                if success:
                    print("  âœ… è®¤çŸ¥åå·®æ¨¡å—å·²é™„åŠ åˆ°ç¯å¢ƒ")
                else:
                    print("  âš ï¸ è®¤çŸ¥åå·®æ¨¡å—é™„åŠ å¤±è´¥ï¼Œå°†è·³è¿‡TTAåå·®è°ƒæ•´")
                self.cognitive_bias_module.reset()
            
            if self.delay_module:
                self.delay_module.reset()
            print("è®¤çŸ¥æ¨¡å—å·²é‡ç½®")
        
        # é‡ç½®å¯è§†åŒ–æ•°æ®è®°å½•å™¨
        if self.enable_visualization and self.data_recorder:
            self.data_recorder.reset_data()
        
        # å¤„ç†è§‚æµ‹ï¼ˆå¯èƒ½åº”ç”¨æ„ŸçŸ¥è¯¯å·®ï¼‰
        obs = self._process_observation(obs)
        
        # # è°ƒè¯•ï¼šæ‰“å°è§‚æµ‹æ•°æ®ç»“æ„å¹¶ä¿å­˜åˆ°æ–‡ä»¶
        # with open("/home/jxy/æ¡Œé¢/1_Project/20250705_computational_cognitive_modeling/computational_cognitive_modeling/metadrive/a_scen_env/metadrive_observation_analysis.txt", "w") as f:
        #     f.write("=== MetaDrive è§‚æµ‹æ•°æ®ç»“æ„åˆ†æ ===\n")
        #     f.write(f"è§‚æµ‹æ•°æ®ç±»å‹: {type(obs)}\n")
            
        #     if isinstance(obs, dict):
        #         f.write(f"è§‚æµ‹å­—å…¸é”®æ•°é‡: {len(obs.keys())}\n")
        #         f.write(f"è§‚æµ‹å­—å…¸é”®: {list(obs.keys())}\n\n")
                
        #         for key, value in obs.items():
        #             f.write(f"é”® '{key}':\n")
        #             f.write(f"  ç±»å‹: {type(value)}\n")
        #             f.write(f"  å½¢çŠ¶: {getattr(value, 'shape', 'N/A')}\n")
                    
        #             if hasattr(value, 'shape') and len(value.shape) == 1:
        #                 if value.shape[0] <= 20:  # å°æ•°ç»„æ˜¾ç¤ºå…¨éƒ¨
        #                     f.write(f"  å†…å®¹: {value}\n")
        #                 else:  # å¤§æ•°ç»„æ˜¾ç¤ºå‰20ä¸ª
        #                     f.write(f"  å†…å®¹(å‰20ä¸ª): {value[:20]}\n")
        #                     f.write(f"  å†…å®¹(å10ä¸ª): {value[-10:]}\n")
        #             elif hasattr(value, 'shape') and len(value.shape) == 2:
        #                 f.write(f"  å†…å®¹(å‰3è¡Œ): {value[:3] if value.shape[0] >= 3 else value}\n")
        #             f.write("\n")
                    
        #     elif isinstance(obs, (list, tuple, np.ndarray)):
        #         obs_array = np.array(obs)
        #         f.write(f"è§‚æµ‹æ•°ç»„å½¢çŠ¶: {obs_array.shape}\n")
        #         f.write(f"è§‚æµ‹æ•°ç»„æ•°æ®ç±»å‹: {obs_array.dtype}\n")
        #         f.write(f"è§‚æµ‹æ•°ç»„æœ€å°å€¼: {np.min(obs_array)}\n")
        #         f.write(f"è§‚æµ‹æ•°ç»„æœ€å¤§å€¼: {np.max(obs_array)}\n")
        #         f.write(f"è§‚æµ‹æ•°ç»„å‡å€¼: {np.mean(obs_array)}\n\n")
                
        #         # åˆ†ææ•°ç»„ç»“æ„
        #         f.write("=== è§‚æµ‹å‘é‡ç»“æ„æ¨æµ‹ ===\n")
        #         if obs_array.shape[0] == 259:
        #             f.write("è¿™æ˜¯MetaDriveçš„æ ‡å‡†è§‚æµ‹å‘é‡(259ç»´)ï¼Œé€šå¸¸åŒ…å«:\n")
        #             f.write("- å‰å‡ ç»´: ä¸»è½¦çŠ¶æ€ (ä½ç½®ã€é€Ÿåº¦ã€æœå‘ç­‰)\n")
        #             f.write("- ä¸­é—´éƒ¨åˆ†: æ¿€å…‰é›·è¾¾æ•°æ® (é€šå¸¸240ç»´)\n") 
        #             f.write("- åé¢éƒ¨åˆ†: è½¦é“çº¿æ£€æµ‹ã€ä¾§é¢æ£€æµ‹å™¨ç­‰\n\n")
                    
        #             f.write(f"å‰20ç»´(ä¸»è½¦çŠ¶æ€): {obs_array[:20]}\n")
        #             f.write(f"ç¬¬21-260ç»´(å¯èƒ½æ˜¯æ¿€å…‰é›·è¾¾): é•¿åº¦{len(obs_array[20:])}")
        #             f.write(f"æ¿€å…‰é›·è¾¾æ•°æ®èŒƒå›´: [{np.min(obs_array[20:]):.3f}, {np.max(obs_array[20:]):.3f}]\n")
        #             f.write(f"æ¿€å…‰é›·è¾¾æ•°æ®å‡å€¼: {np.mean(obs_array[20:]):.3f}\n")
                
        #         f.write(f"\nå®Œæ•´è§‚æµ‹å‘é‡:\n{obs_array}\n")
            
        #     f.write("================================\n")
        
        # print("è§‚æµ‹æ•°æ®åˆ†æå·²ä¿å­˜åˆ°: /tmp/metadrive_observation_analysis.txt")
        
        
        # è¿”å›ä¸çˆ¶ç±»ç›¸åŒçš„æ ¼å¼
        if isinstance(reset_result, tuple):
            return obs, reset_info
        else:
            return obs
    
    def _get_ego_state_for_cognitive_modules(self):
        """
        ä¸ºè®¤çŸ¥æ¨¡å—è·å–ä¸»è½¦çŠ¶æ€ä¿¡æ¯
        
        Returns:
            dict: åŒ…å«ä¸»è½¦çŠ¶æ€çš„å­—å…¸
        """
        agent = self.agent
        
        # è®¤çŸ¥æ¨¡å—éœ€è¦çš„å…³é”®çŠ¶æ€ä¿¡æ¯
        ego_state = {
            # ç”¨äºæ„ŸçŸ¥æ¨¡å—çš„ä½ç½®ä¿¡æ¯
            'position_x': agent.position[0],
            'position_y': agent.position[1],
            
            # ç”¨äºå»¶è¿Ÿæ¨¡å—çš„åŠ¨åŠ›å­¦ä¿¡æ¯
            'speed': agent.speed,
            'heading': agent.heading_theta,
            'velocity_x': agent.velocity[0],
            'velocity_y': agent.velocity[1],
            
            # ç”¨äºå®‰å…¨è¯„ä¼°çš„è½¦é“ä¿¡æ¯
            'on_lane': agent.on_lane,
            'out_of_road': agent.out_of_road,
            'dist_to_left_side': agent.dist_to_left_side,
            'dist_to_right_side': agent.dist_to_right_side
        }
        
        return ego_state
    
    def _process_observation(self, obs):
        """
        å¤„ç†è§‚æµ‹æ•°æ®ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰
        æ³¨æ„ï¼šæ–°çš„çŠ¶æ€å¤„ç†ä¸»è¦åœ¨step()æ–¹æ³•ä¸­çš„process_vehicle_state()è¿›è¡Œ
        """
        if not self.enable_cognitive_modules or not self.perception_module:
            return obs
        
        # è°ƒè¯•ï¼šæ‰“å°è§‚æµ‹æ•°æ®ç±»å‹å’Œç»“æ„ï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
        if not hasattr(self, '_obs_type_printed'):
            print(f"\n[è°ƒè¯•] è§‚æµ‹æ•°æ®ç±»å‹: {type(obs)}")
            if isinstance(obs, dict):
                print(f"[è°ƒè¯•] è§‚æµ‹å­—å…¸é”®: {list(obs.keys())[:5]}...")  # åªæ‰“å°å‰5ä¸ªé”®
            elif isinstance(obs, tuple):
                print(f"[è°ƒè¯•] è§‚æµ‹æ˜¯å…ƒç»„ï¼Œé•¿åº¦: {len(obs)}")
                if len(obs) == 2:
                    print(f"[è°ƒè¯•] å…ƒç»„ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(obs[0])}")
                    print(f"[è°ƒè¯•] å…ƒç»„ç¬¬äºŒä¸ªå…ƒç´ ç±»å‹: {type(obs[1])}")
                    # åœ¨Gymä¸­ï¼Œreset()é€šå¸¸è¿”å›(observation, info)
                    # æˆ‘ä»¬åªéœ€è¦observationéƒ¨åˆ†
                    if isinstance(obs[0], dict):
                        print(f"[è°ƒè¯•] å®é™…è§‚æµ‹æ˜¯å­—å…¸ï¼Œé”®: {list(obs[0].keys())[:5]}...")
            elif isinstance(obs, (list, np.ndarray)):
                print(f"[è°ƒè¯•] è§‚æµ‹æ•°ç»„å½¢çŠ¶: {np.array(obs).shape}")
            self._obs_type_printed = True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºPPOä¸“å®¶æ¨¡å¼
        is_ppo_mode = (
            self.control_manager.expert_mode and 
            not self.disable_ppo_expert and
            hasattr(self.agent, 'expert_takeover') and 
            self.agent.expert_takeover
        )
        
        # ä¿ç•™åŸæœ‰çš„è§‚æµ‹å¤„ç†é€»è¾‘ï¼ˆå…¼å®¹æ€§ï¼Œä½†ä¸»è¦å¤„ç†å·²åœ¨stepä¸­å®Œæˆï¼‰
        if is_ppo_mode:
            # è·å–ä¸»è½¦çŠ¶æ€
            ego_state = np.array([
                self.agent.position[0],
                self.agent.position[1]
            ])
            
            # åº”ç”¨æ„ŸçŸ¥å¤„ç†ï¼ˆè¿™ä¸»è¦æ˜¯å…¼å®¹æ€§å¤„ç†ï¼Œæ ¸å¿ƒå¤„ç†åœ¨process_vehicle_stateä¸­ï¼‰
            processed_obs = self.perception_module.process_observation(
                obs, ego_state, is_ppo_mode=True
            )
            
            return processed_obs
        
        return obs
    
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥ä»¿çœŸï¼Œé›†æˆè®¤çŸ¥æ¨¡å—å¤„ç†"""
        # å®æ—¶æ§åˆ¶
        if self.enable_realtime and self._last_step_time is not None:
            current_time = self._real_time_module.time()
            target_step_duration = 1.0 / self.target_fps
            elapsed_since_last_step = current_time - self._last_step_time
            
            if elapsed_since_last_step < target_step_duration:
                sleep_duration = target_step_duration - elapsed_since_last_step
                self._real_time_module.sleep(sleep_duration)
            
            self._last_step_time = self._real_time_module.time()
        
        # æ›´æ–°ä»¿çœŸæ—¶é—´
        decision_repeat = self.engine.global_config.get('decision_repeat', 1)
        effective_time_step = self.physics_world_step_size * decision_repeat
        self._simulation_time += effective_time_step
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºPPOä¸“å®¶æ¨¡å¼
        is_ppo_mode = (
            self.control_manager.expert_mode and 
            not self.disable_ppo_expert and
            hasattr(self.agent, 'expert_takeover') and 
            self.agent.expert_takeover and
            not self.control_manager.use_trajectory_for_main  # éè½¨è¿¹é‡æ”¾æ¨¡å¼
        )
        
        # æ›´æ–°æ§åˆ¶ç®¡ç†å™¨
        self.control_manager.set_step_count(self._step_count)
        
        # è·å–åŠ¨ä½œ
        action, action_info = self.control_manager.get_action(action)
        
        # åº”ç”¨æ‰§è¡Œå»¶è¿Ÿï¼ˆä»…PPOæ¨¡å¼ï¼‰
        if self.enable_cognitive_modules and self.delay_module and is_ppo_mode:
            original_action = action.copy() if isinstance(action, np.ndarray) else list(action)
            action = self.delay_module.process_action(action, is_ppo_mode=True)
            
            if self._step_count % 50 == 0:
                action_diff = np.linalg.norm(np.array(action) - np.array(original_action))
                print(f"[è®¤çŸ¥å»¶è¿Ÿ] PPOæ¨¡å¼ - åº”ç”¨æ‰§è¡Œå»¶è¿Ÿ (delay={self.delay_module.delay_steps} steps, diff={action_diff:.3f})")
        
        # === æ—§é€»è¾‘ï¼šå·²åºŸå¼ƒï¼Œå™ªå£°ç°åœ¨åœ¨é›·è¾¾ä¼ æ„Ÿå™¨å±‚æ³¨å…¥ ===
        # ä¸å†åœ¨æ­¤å¤„ä¿®æ”¹agentçŠ¶æ€ï¼Œå™ªå£°ç›´æ¥åœ¨é›·è¾¾ä¼ æ„Ÿå™¨çš„perceiveæ–¹æ³•ä¸­æ³¨å…¥
        # if self.enable_cognitive_modules and self.perception_module and is_ppo_mode:
        #     ego_state = self._get_ego_state_for_cognitive_modules()
        #     self.perception_module.process_vehicle_state(agent=self.agent, ego_state=ego_state, is_ppo_mode=True)
        #     if self._step_count % 50 == 0:
        #         print(f"[è®¤çŸ¥æ„ŸçŸ¥] PPOæ¨¡å¼ - å¯¹agentçŠ¶æ€åº”ç”¨æ„ŸçŸ¥å™ªå£°å’Œå¡å°”æ›¼æ»¤æ³¢")
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, reward, terminated, truncated, info = super().step(action)
        
        # åº”ç”¨è®¤çŸ¥åå·®è°ƒæ•´å¥–åŠ±ï¼ˆä»…PPOæ¨¡å¼ï¼‰
        if self.enable_cognitive_modules and self.cognitive_bias_module and is_ppo_mode:
            original_reward = reward
            adjusted_reward, bias_info = self.cognitive_bias_module.process_reward(
                original_reward=reward,
                env=self,
                info=info,
                is_ppo_mode=is_ppo_mode
            )
            reward = adjusted_reward
            
            # å°†åå·®ä¿¡æ¯æ·»åŠ åˆ°infoå­—å…¸
            info['cognitive_bias_info'] = bias_info
            info['original_reward'] = original_reward
            info['bias_applied'] = bias_info['bias_applied']
            
            if self._step_count % 50 == 0 and bias_info['bias_active']:
                print(f"[è®¤çŸ¥åå·®] PPOæ¨¡å¼ - åº”ç”¨TTAé£é™©åŒæ¶ (inverse_tta={bias_info['inverse_tta']:.3f}, bias={bias_info['bias_applied']:.3f})")
        
        # ä¿ç•™åŸæœ‰çš„è§‚æµ‹å¤„ç†æ–¹æ³•ï¼ˆå…¼å®¹æ€§ï¼‰
        obs = self._process_observation(obs)
        
        # è®°å½•è®¤çŸ¥æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_visualization and self.data_recorder:
            self.data_recorder.record_step(
                step_count=self._step_count,
                timestamp=self._simulation_time,
                env=self,
                obs=obs,
                action=action,
                action_info=action_info,
                reward=reward,
                info=info,
                cognitive_active=is_ppo_mode and self.enable_cognitive_modules
            )
        
        # è®°å½•è§‚æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.observation_recorder:
            self.observation_recorder.record_step(
                env=self,
                action=action,
                action_info=action_info,
                obs=obs,
                reward=reward,
                info=info,
                step_count=self._step_count
            )
        
        # é‡æ”¾èƒŒæ™¯è½¦
        self._replay_all_vehicles_by_time()
        
        # æ¸…ç†å·²ç»“æŸçš„èƒŒæ™¯è½¦
        self._cleanup_finished_trajectories()
        
        self._step_count += 1
        
        # æ£€æŸ¥ç»“æŸæ¡ä»¶
        crash_flag = info.get("crash", False) or info.get("crash_vehicle", False)
        out_of_road_flag = info.get("out_of_road", False)
        arrive_dest_flag = info.get("arrive_dest", False)
        horizon_reached_flag = (self._step_count >= self.max_step)
        
        should_end = False
        if crash_flag and self.end_on_crash:
            should_end = True
        if out_of_road_flag and self.end_on_out_of_road:
            should_end = True
        if arrive_dest_flag and self.end_on_arrive_dest:
            should_end = True
        if horizon_reached_flag and self.end_on_horizon:
            should_end = True
        
        done = bool(should_end)
        
        # æ·»åŠ ä¿¡æ¯
        info["simulation_time"] = self._simulation_time
        info["cognitive_modules_active"] = self.enable_cognitive_modules and is_ppo_mode
        
        # æ·»åŠ æ§åˆ¶æ¨¡å¼ä¿¡æ¯
        control_status = self.control_manager.get_control_status()
        info.update(control_status)
        info["action_source"] = action_info.get("source", "unknown")
        
        return obs, reward, done, info
    
    def render(self, *args, **kwargs):
        """æ¸²æŸ“ç¯å¢ƒï¼Œæ˜¾ç¤ºè®¤çŸ¥æ¨¡å—çŠ¶æ€"""
        render_text = kwargs.get("text", {})
        
        # è·å–æ§åˆ¶çŠ¶æ€
        control_status = self.control_manager.get_control_status()
        render_text.update(control_status)
        
        # æ·»åŠ è®¤çŸ¥æ¨¡å—çŠ¶æ€
        if self.enable_cognitive_modules:
            is_ppo_mode = (
                self.control_manager.expert_mode and 
                not self.disable_ppo_expert and
                hasattr(self.agent, 'expert_takeover') and 
                self.agent.expert_takeover
            )
            
            cognitive_status = "Active (PPO)" if is_ppo_mode else "Inactive"
            render_text["Cognitive Modules"] = cognitive_status
            
            if self.perception_module:
                render_text["Perception"] = f"sigma={self.perception_module.sigma:.2f}"
            if self.delay_module:
                render_text["Delay"] = f"{self.delay_module.delay_steps} steps"
        
        # å…¶ä»–ä¿¡æ¯
        render_text.update({
            "Step": f"{self._step_count}/{self.max_step}",
            "Simulation Time": f"{self._simulation_time:.1f}s",
            "Main Car Speed": f"{self.agent.speed:.1f} m/s",
            "Background Vehicles": f"{len(self.ghost_vehicles)}",
        })
        
        kwargs["text"] = render_text
        return super().render(*args, **kwargs)
    
    def _cleanup_ghost_vehicles(self):
        """æ¸…ç†èƒŒæ™¯è½¦"""
        for vid, vehicle in self.ghost_vehicles.items():
            try:
                vehicle.destroy()
            except:
                pass
        self.ghost_vehicles = {}
    
    def _cleanup_finished_trajectories(self):
        """æ¸…ç†å·²ç»“æŸè½¨è¿¹çš„èƒŒæ™¯è½¦"""
        if not self.enable_background_vehicles:
            return
        
        vehicles_to_remove = []
        for vid, vehicle in self.ghost_vehicles.items():
            if vid in self.trajectory_dict:
                traj = self.trajectory_dict[vid]
                if self._is_trajectory_finished(traj, self._simulation_time):
                    vehicles_to_remove.append(vid)
        
        for vid in vehicles_to_remove:
            if vid in self.ghost_vehicles:
                vehicle = self.ghost_vehicles[vid]
                try:
                    vehicle.destroy()
                except Exception as e:
                    pass
                del self.ghost_vehicles[vid]
    
    def _is_trajectory_finished(self, trajectory, sim_time):
        """æ£€æŸ¥è½¨è¿¹æ˜¯å¦å·²ç»“æŸ"""
        if not trajectory:
            return True
        
        target_time = self._trajectory_start_time + sim_time
        
        if "timestamp" in trajectory[0]:
            last_timestamp = trajectory[-1]["timestamp"]
            return target_time > last_timestamp
        else:
            max_steps = len(trajectory)
            current_step = int(sim_time / self.physics_world_step_size)
            return current_step >= max_steps
    
    def _get_trajectory_state_at_time(self, trajectory, sim_time):
        """æ ¹æ®ä»¿çœŸæ—¶é—´è·å–è½¨è¿¹çŠ¶æ€"""
        if not trajectory:
            return None
        
        target_time = self._trajectory_start_time + sim_time
        
        if "timestamp" in trajectory[0]:
            # åŸºäºæ—¶é—´æˆ³æŸ¥æ‰¾
            timestamps = [point["timestamp"] for point in trajectory]
            
            if target_time <= timestamps[0]:
                return trajectory[0]
            elif target_time >= timestamps[-1]:
                return trajectory[-1]
            
            # çº¿æ€§æ’å€¼
            for i in range(len(timestamps) - 1):
                if timestamps[i] <= target_time <= timestamps[i + 1]:
                    t0, t1 = timestamps[i], timestamps[i + 1]
                    p0, p1 = trajectory[i], trajectory[i + 1]
                    
                    alpha = (target_time - t0) / (t1 - t0) if t1 != t0 else 0.0
                    
                    interpolated_state = {
                        "x": p0["x"] + alpha * (p1["x"] - p0["x"]),
                        "y": p0["y"] + alpha * (p1["y"] - p0["y"]),
                        "speed": p0["speed"] + alpha * (p1["speed"] - p0["speed"]),
                        "heading": p0["heading"] + alpha * (p1["heading"] - p0["heading"]),
                        "timestamp": target_time
                    }
                    
                    return interpolated_state
        else:
            # åŸºäºæ­¥æ•°ç´¢å¼•
            step_index = int(sim_time / self.physics_world_step_size)
            if 0 <= step_index < len(trajectory):
                return trajectory[step_index]
        
        return None
    
    def _replay_all_vehicles_by_time(self):
        """é‡æ”¾èƒŒæ™¯è½¦è½¨è¿¹"""
        if not self.enable_background_vehicles:
            return
        
        for vid, traj in self.trajectory_dict.items():
            state = self._get_trajectory_state_at_time(traj, self._simulation_time)
            
            if state is None:
                if vid in self.ghost_vehicles:
                    vehicle = self.ghost_vehicles[vid]
                    try:
                        vehicle.destroy()
                    except:
                        pass
                    del self.ghost_vehicles[vid]
                continue
            
            if vid not in self.ghost_vehicles:
                # åˆ›å»ºæ–°èƒŒæ™¯è½¦
                vehicle_config = self.engine.global_config["vehicle_config"].copy()
                vehicle_config.update({
                    "show_navi_mark": False,
                    "show_dest_mark": False,
                    "show_line_to_dest": False,
                    "show_line_to_navi_mark": False,
                    "show_navigation_arrow": False,
                    "use_special_color": False,
                })
                
                v = self.engine.spawn_object(
                    DefaultVehicle, 
                    vehicle_config=vehicle_config, 
                    position=[0, 0], 
                    heading=0
                )
                
                self.ghost_vehicles[vid] = v
            else:
                v = self.ghost_vehicles[vid]
            
            # æ›´æ–°èƒŒæ™¯è½¦ä½ç½®
            v.set_position([state["x"], state["y"]])
            v.set_heading_theta(state["heading"])
            
            speed_magnitude = state["speed"]
            if speed_magnitude > 0.01:
                direction = [np.cos(state["heading"]), np.sin(state["heading"])]
                v.set_velocity(direction, speed_magnitude)
            else:
                v.set_velocity([1.0, 0.0], 0.0)
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        # ç”Ÿæˆè®¤çŸ¥æ„ŸçŸ¥æ¨¡å—çš„cog_influenceå¯è§†åŒ–ï¼ˆåœ¨detach_from_envä¹‹å‰ï¼‰
        if self.enable_cognitive_modules and self.perception_module and hasattr(self.perception_module, 'generate_visualization'):
            try:
                print(f"\nå¼€å§‹ç”Ÿæˆè®¤çŸ¥æ„ŸçŸ¥å½±å“åˆ†æå›¾è¡¨...")
                cog_influence_dir = self.perception_module.generate_visualization(env=self)
                print(f"âœ… è®¤çŸ¥æ„ŸçŸ¥å½±å“å›¾è¡¨å·²ä¿å­˜åˆ° {cog_influence_dir}")
            except Exception as e:
                print(f"âŒ ç”Ÿæˆè®¤çŸ¥æ„ŸçŸ¥å½±å“å›¾è¡¨å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # ç”Ÿæˆè®¤çŸ¥åå·®æ¨¡å—çš„å¯è§†åŒ–ï¼ˆæ–°å¢ï¼‰
        if self.enable_cognitive_modules and self.cognitive_bias_module and hasattr(self.cognitive_bias_module, 'generate_visualization'):
            try:
                print(f"\nå¼€å§‹ç”Ÿæˆè®¤çŸ¥åå·®åˆ†æå›¾è¡¨...")
                bias_dir = self.cognitive_bias_module.generate_visualization(env=self)
                print(f"âœ… è®¤çŸ¥åå·®åˆ†æå›¾è¡¨å·²ä¿å­˜åˆ° {bias_dir}")
                
                # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
                stats = self.cognitive_bias_module.get_statistics()
                print(f"\nè®¤çŸ¥åå·®ç»Ÿè®¡ä¿¡æ¯:")
                print(f"  æ€»æ­¥æ•°: {stats['total_steps']}")
                print(f"  æ¿€æ´»ç‡: {stats['activation_rate']:.2%}")
                print(f"  å¹³å‡åå·®: {stats['average_bias']:.4f}")
                print(f"  æ€»åå·®: {stats['total_bias']:.2f}")
            except Exception as e:
                print(f"âŒ ç”Ÿæˆè®¤çŸ¥åå·®åˆ†æå›¾è¡¨å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # åˆ†ç¦»å™ªå£°é›·è¾¾ï¼Œæ¢å¤åŸå§‹ä¼ æ„Ÿå™¨ï¼ˆåœ¨å¯è§†åŒ–ä¹‹åï¼‰
        if self.enable_cognitive_modules and self.perception_module:
            self.perception_module.detach_from_env()
        
        # åˆ†ç¦»è®¤çŸ¥åå·®æ¨¡å—ï¼ˆæ–°å¢ï¼‰
        if self.enable_cognitive_modules and self.cognitive_bias_module:
            self.cognitive_bias_module.detach_from_env()
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        if self.enable_visualization and self.data_recorder and self.visualizer:
            try:
                from datetime import datetime
                session_name = f"cognitive_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                print(f"\nå¼€å§‹ç”Ÿæˆè®¤çŸ¥åˆ†æå›¾è¡¨...")
                self.visualizer.generate_all_plots(self.data_recorder, session_name)
                print(f"âœ… è®¤çŸ¥åˆ†æå›¾è¡¨å·²ä¿å­˜åˆ° {self.visualization_output_dir}")
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
        
        if self.observation_recorder:
            self.observation_recorder.finalize_recording()

        self._cleanup_ghost_vehicles()
        super().close()

    def _debug_navigation_info(self):
        """
        è°ƒè¯•å¯¼èˆªä¿¡æ¯ï¼Œæ£€æŸ¥å¯¼èˆªç³»ç»Ÿæ˜¯å¦æ­£ç¡®é…ç½®
        """
        if hasattr(self.agent, 'navigation') and self.agent.navigation:
            nav = self.agent.navigation
            print(f"\n=== Navigation Debug Info ===")
            print(f"Navigation module: {type(nav).__name__}")
            print(f"Current lane: {nav.current_lane.index if nav.current_lane else 'None'}")
            print(f"Destination: {getattr(nav, 'final_lane', 'Not set')}")
            print(f"Route length: {len(getattr(nav, 'route', []))}")
            print(f"Route completion: {nav.route_completion:.3f}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å¯¼èˆªè·¯å¾„
            if hasattr(nav, 'route') and nav.route and len(nav.route) > 1:
                print(f"âœ… Navigation route established: {nav.route[:3]}{'...' if len(nav.route) > 3 else ''}")
            else:
                print(f"âŒ Warning: No valid navigation route found!")
                print(f"   This may cause PPO expert to remain stationary")
                
                # ğŸ”§ è‡ªåŠ¨ä¿®å¤å¯¼èˆªè·¯å¾„
                print(f"ğŸš€ å°è¯•è‡ªåŠ¨ä¿®å¤å¯¼èˆªè·¯å¾„...")
                try:
                    from fix_navigation_route import fix_navigation_for_env
                    success = fix_navigation_for_env(self)
                    if success:
                        print(f"âœ… å¯¼èˆªè·¯å¾„ä¿®å¤æˆåŠŸ!")
                        # é‡æ–°æ£€æŸ¥è·¯å¾„
                        if hasattr(nav, 'route') and nav.route and len(nav.route) > 1:
                            print(f"âœ… ä¿®å¤åè·¯å¾„: {nav.route[:3]}{'...' if len(nav.route) > 3 else ''}")
                    else:
                        print(f"âŒ å¯¼èˆªè·¯å¾„ä¿®å¤å¤±è´¥ï¼ŒPPOå¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
                except ImportError:
                    print(f"âš ï¸ å¯¼èˆªä¿®å¤æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ fix_navigation_route.py æ–‡ä»¶")
                except Exception as e:
                    print(f"âŒ å¯¼èˆªä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                
            # æ£€æŸ¥ç›®æ ‡è·ç¦»
            if hasattr(nav, 'distance_to_destination'):
                print(f"Distance to destination: {nav.distance_to_destination:.1f}m")
            
            # æ˜¾ç¤ºè‡ªå®šä¹‰ç›®æ ‡ç‚¹ä¿¡æ¯
            if hasattr(self, 'custom_destination'):
                dest = self.custom_destination
                agent_pos = self.agent.position
                distance_to_custom_dest = np.sqrt((agent_pos[0] - dest[0])**2 + (agent_pos[1] - dest[1])**2)
                print(f"Custom destination: ({dest[0]:.1f}, {dest[1]:.1f})")
                print(f"Distance to custom dest: {distance_to_custom_dest:.1f}m")
            
            print(f"=============================\n")
        else:
            print(f"âŒ Error: Agent has no navigation module!")

    def _set_custom_destination(self):
        """
        è®¾ç½®è‡ªå®šä¹‰ç›®æ ‡ç‚¹ï¼šæ‰€æœ‰è½¦è¾†è½¨è¿¹ä¸­xåæ ‡çš„æœ€å¤§å€¼ï¼Œyåæ ‡è®¾ç½®ä¸ºåˆé€‚çš„è½¦é“ä½ç½®
        """
        # è®¡ç®—è½¨è¿¹æ•°æ®ä¸­xåæ ‡çš„æœ€å¤§å€¼
        max_x = float('-inf')
        target_y = 0.0  # é»˜è®¤yåæ ‡
        
        # æ ¹æ®enable_background_vehicleså‚æ•°å†³å®šæ˜¯å¦åŒ…å«èƒŒæ™¯è½¦
        if self.enable_background_vehicles and self.trajectory_dict:
            for vehicle_id, trajectory in self.trajectory_dict.items():
                for point in trajectory:
                    if point["x"] > max_x:
                        max_x = point["x"]
                        target_y = point["y"]  # ä½¿ç”¨è¾¾åˆ°æœ€å¤§xæ—¶çš„yåæ ‡ä½œä¸ºå‚è€ƒ
        
        # å¦‚æœæœ‰ä¸»è½¦è½¨è¿¹ï¼Œä¹ŸåŒ…å«åœ¨è®¡ç®—ä¸­
        if self.main_vehicle_trajectory:
            for point in self.main_vehicle_trajectory:
                if point["x"] > max_x:
                    max_x = point["x"]
                    target_y = point["y"]
        
        if max_x == float('-inf'):
            print("Warning: Could not calculate destination from trajectory data")
            # å¦‚æœæ²¡æœ‰è½¨è¿¹æ•°æ®ï¼Œè®¾ç½®ä¸€ä¸ªé»˜è®¤çš„è¿œå¤„ç›®æ ‡
            max_x = 500.0  # é»˜è®¤500ç±³è¿œçš„ç›®æ ‡
            target_y = 0.0
            print(f"Using default destination: ({max_x:.1f}, {target_y:.1f})")
        
        if not self.enable_background_vehicles:
            print("Note: Destination calculated from main vehicle trajectory only (background vehicles disabled)")
            
        target_position = [max_x, target_y]
        print(f"\n=== Custom Destination Setup ===")
        print(f"Calculated destination: ({max_x:.1f}, {target_y:.1f})")
        
        # å°è¯•æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡ä½ç½®çš„è½¦é“
        try:
            # ä½¿ç”¨MetaDriveçš„è½¦é“å®šä½åŠŸèƒ½æ‰¾åˆ°æœ€è¿‘çš„è½¦é“
            if hasattr(self.engine, 'current_map') and self.engine.current_map:
                current_map = self.engine.current_map
                
                # æŸ¥æ‰¾æœ€æ¥è¿‘ç›®æ ‡ä½ç½®çš„è½¦é“
                closest_lane = None
                min_distance = float('inf')
                
                for road in current_map.road_network.graph.keys():
                    for lane_index in current_map.road_network.graph[road].keys():
                        lane = current_map.road_network.get_lane((road, lane_index))
                        if lane:
                            # è®¡ç®—è½¦é“ä¸­å¿ƒçº¿ä¸Šæœ€æ¥è¿‘ç›®æ ‡ç‚¹çš„ä½ç½®
                            lane_length = lane.length
                            # æ£€æŸ¥è½¦é“æœ«ç«¯ä½ç½®
                            end_position = lane.position(lane_length, 0)
                            distance = np.sqrt((end_position[0] - max_x)**2 + (end_position[1] - target_y)**2)
                            
                            if distance < min_distance:
                                min_distance = distance
                                closest_lane = lane
                                # æ›´æ–°ç›®æ ‡yåæ ‡ä¸ºè½¦é“ä¸­å¿ƒ
                                target_y = end_position[1]
                
                if closest_lane:
                    target_position = [max_x, target_y]
                    print(f"Adjusted destination to nearest lane: ({max_x:.1f}, {target_y:.1f})")
                    print(f"Target lane: {closest_lane.index}")
                    
                    # è®¾ç½®å¯¼èˆªç›®æ ‡ - ä¿®å¤ç‰ˆæœ¬
                    if hasattr(self.agent, 'navigation') and self.agent.navigation:
                        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨PGåœ°å›¾çš„æ­£ç¡®å¯¼èˆªè®¾ç½®
                        navigation_success = self._fix_pg_map_navigation()
                        
                        if not navigation_success:
                            # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•åŸæœ‰é€»è¾‘
                            try:
                                # æŸ¥æ‰¾åŒ…å«ç›®æ ‡ä½ç½®çš„è½¦é“ç´¢å¼•
                                target_lane_index = closest_lane.index
                                self.agent.navigation.set_route(
                                    self.agent.navigation.current_lane.index,
                                    target_lane_index
                                )
                                print(f"âœ… Navigation route set to lane: {target_lane_index}")
                                navigation_success = True
                            except Exception as e:
                                print(f"âš ï¸  Could not set navigation route: {e}")
                                # æ‰‹åŠ¨è®¾ç½®ç›®æ ‡ä½ç½®
                                if hasattr(self.agent.navigation, 'destination_point'):
                                    self.agent.navigation.destination_point = target_position
                                    print(f"ğŸ”§ Fall back to manual destination: {target_position}")
                        
                        # å¦‚æœæ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥ï¼Œè°ƒç”¨å¤–éƒ¨ä¿®å¤æ¨¡å—
                        if not navigation_success:
                            print(f"ğŸš¨ æ‰€æœ‰å¯¼èˆªè®¾ç½®éƒ½å¤±è´¥ï¼Œè°ƒç”¨å¤–éƒ¨ä¿®å¤æ¨¡å—...")
                            try:
                                from fix_navigation_route import fix_navigation_for_env
                                success = fix_navigation_for_env(self)
                                if success:
                                    print(f"âœ… å¤–éƒ¨ä¿®å¤æ¨¡å—æˆåŠŸä¿®å¤å¯¼èˆª!")
                                else:
                                    print(f"âŒ å¤–éƒ¨ä¿®å¤æ¨¡å—ä¹Ÿæ— æ³•ä¿®å¤å¯¼èˆª")
                            except ImportError:
                                print(f"âš ï¸ å¤–éƒ¨ä¿®å¤æ¨¡å—æœªæ‰¾åˆ°")
                            except Exception as repair_e:
                                print(f"âŒ å¤–éƒ¨ä¿®å¤æ¨¡å—å‡ºé”™: {repair_e}")
                else:
                    print(f"Warning: Could not find suitable lane for destination")
                    
        except Exception as e:
            print(f"Error in destination setup: {e}")
            
        # å­˜å‚¨ç›®æ ‡ä½ç½®ä¾›è°ƒè¯•ä½¿ç”¨
        self.custom_destination = target_position
        print(f"Final destination: ({target_position[0]:.1f}, {target_position[1]:.1f})")
        print(f"================================\n")

    def _fix_pg_map_navigation(self):
        """
        ä¿®å¤PGåœ°å›¾ï¼ˆç¨‹åºåŒ–ç”Ÿæˆåœ°å›¾ï¼‰çš„å¯¼èˆªè·¯å¾„
        ä¸“é—¨é’ˆå¯¹ "S"*8 ç±»å‹çš„ç›´çº¿åœ°å›¾
        
        Returns:
            bool: ä¿®å¤æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ”§ å°è¯•ä¿®å¤PGåœ°å›¾å¯¼èˆªè·¯å¾„...")
        
        try:
            # è·å–å½“å‰åœ°å›¾å’Œé“è·¯ç½‘ç»œ
            current_map = self.engine.current_map
            road_network = current_map.road_network
            
            # è·å–å½“å‰è½¦é“
            current_lane = self.agent.navigation.current_lane
            if not current_lane:
                print(f"âŒ æ— æ³•è·å–å½“å‰è½¦é“")
                return False
            
            current_lane_index = current_lane.index
            print(f"ğŸ“ å½“å‰è½¦é“: {current_lane_index}")
            
            # ç­–ç•¥1: æŸ¥æ‰¾åœ°å›¾ä¸­çš„æœ€åä¸€ä¸ªè½¦é“æ®µä½œä¸ºç›®æ ‡
            all_road_segments = list(road_network.graph.keys())
            print(f"ğŸ—ºï¸ åœ°å›¾åŒ…å« {len(all_road_segments)} ä¸ªé“è·¯æ®µ: {all_road_segments}")
            
            # å¯¹äº "S"*8 ç±»å‹çš„åœ°å›¾ï¼ŒæŸ¥æ‰¾æœ€è¿œçš„è½¦é“
            target_lane_index = None
            max_distance = 0
            
            for road_start in all_road_segments:
                for road_end in road_network.graph[road_start].keys():
                    for lane_idx, lane in road_network.graph[road_start][road_end].items():
                        if lane:
                            # è®¡ç®—è½¦é“æœ«ç«¯ä½ç½®
                            lane_end_pos = lane.position(lane.length, 0)
                            # è®¡ç®—è·ç¦»å½“å‰ä½ç½®çš„è·ç¦»
                            current_pos = self.agent.position
                            distance = np.sqrt((lane_end_pos[0] - current_pos[0])**2 + 
                                             (lane_end_pos[1] - current_pos[1])**2)
                            
                            if distance > max_distance:
                                max_distance = distance
                                target_lane_index = (road_start, road_end, lane_idx)
                                print(f"ğŸ¯ æ‰¾åˆ°æ›´è¿œçš„ç›®æ ‡è½¦é“: {target_lane_index}, è·ç¦»: {distance:.1f}m")
            
            if target_lane_index:
                print(f"ğŸ¯ è®¾ç½®å¯¼èˆªè·¯å¾„:")
                print(f"  èµ·å§‹è½¦é“: {current_lane_index}")
                print(f"  ç›®æ ‡è½¦é“: {target_lane_index}")
                print(f"  ç›®æ ‡è·ç¦»: {max_distance:.1f}m")
                
                # å°è¯•è®¾ç½®è·¯å¾„
                self.agent.navigation.set_route(current_lane_index, target_lane_index)
                
                # éªŒè¯è·¯å¾„æ˜¯å¦æˆåŠŸè®¾ç½®
                if hasattr(self.agent.navigation, 'route') and self.agent.navigation.route:
                    print(f"âœ… PGåœ°å›¾å¯¼èˆªè·¯å¾„è®¾ç½®æˆåŠŸ!")
                    print(f"ğŸ“ è·¯å¾„: {self.agent.navigation.route[:3]}{'...' if len(self.agent.navigation.route) > 3 else ''}")
                    return True
                else:
                    print(f"âŒ è·¯å¾„è®¾ç½®åéªŒè¯å¤±è´¥")
                    return False
            else:
                print(f"âŒ æœªæ‰¾åˆ°åˆé€‚çš„ç›®æ ‡è½¦é“")
                return False
                
        except Exception as e:
            print(f"âŒ PGåœ°å›¾å¯¼èˆªä¿®å¤å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _find_next_lane(self, current_lane, road_network):
        """å¯»æ‰¾å½“å‰è½¦é“çš„ä¸‹ä¸€ä¸ªè½¦é“"""
        
        try:
            current_index = current_lane.index
            
            # è§£æå½“å‰è½¦é“ç´¢å¼•
            if len(current_index) >= 3:
                current_start = current_index[0]
                current_end = current_index[1]
                lane_idx = current_index[2]
                
                # åœ¨é“è·¯ç½‘ç»œä¸­å¯»æ‰¾ä»¥current_endä¸ºèµ·ç‚¹çš„è½¦é“
                if current_end in road_network.graph:
                    for next_end in road_network.graph[current_end].keys():
                        lanes = road_network.graph[current_end][next_end]
                        
                        # å¤„ç†ä¸åŒçš„lanesæ•°æ®ç»“æ„
                        if hasattr(lanes, 'items'):
                            lane_items = lanes.items()
                        elif isinstance(lanes, (list, tuple)):
                            lane_items = enumerate(lanes)
                        else:
                            continue
                        
                        for next_lane_idx, next_lane in lane_items:
                            if next_lane and next_lane_idx == lane_idx:  # ä¿æŒç›¸åŒçš„è½¦é“ç¼–å·
                                return next_lane
                                
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸åŒç¼–å·çš„è½¦é“ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨è½¦é“
                        for next_lane_idx, next_lane in lane_items:
                            if next_lane:
                                return next_lane
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ æŸ¥æ‰¾ä¸‹ä¸€ä¸ªè½¦é“å¤±è´¥: {e}")
            return None

    def _fix_lane_detection(self):
        """ä¿®å¤è½¦é“æ£€æµ‹é—®é¢˜ - æ ¹æ®ä¸»è½¦å®é™…ä½ç½®é‡æ–°æ£€æµ‹æ­£ç¡®çš„å½“å‰è½¦é“"""
        
        print("ğŸ”§ å¼€å§‹ä¿®å¤è½¦é“æ£€æµ‹...")
        
        try:
            agent = self.agent
            navigation = agent.navigation
            current_map = self.engine.current_map
            road_network = current_map.road_network
            agent_pos = agent.position
            
            print(f"ğŸ“ ä¸»è½¦å®é™…ä½ç½®: ({agent_pos[0]:.1f}, {agent_pos[1]:.1f})")
            print(f"âŒ é”™è¯¯æ£€æµ‹è½¦é“: {navigation.current_lane.index}")
            
            # æ‰¾åˆ°ä¸»è½¦çœŸæ­£æ‰€åœ¨çš„è½¦é“
            best_lane = None
            min_distance = float('inf')
            
            for road_start in road_network.graph.keys():
                for road_end in road_network.graph[road_start].keys():
                    lanes = road_network.graph[road_start][road_end]
                    
                    # å¤„ç†ä¸åŒçš„lanesæ•°æ®ç»“æ„
                    if hasattr(lanes, 'items'):
                        lane_items = lanes.items()
                    elif isinstance(lanes, (list, tuple)):
                        lane_items = enumerate(lanes)
                    else:
                        continue
                    
                    for lane_idx, lane in lane_items:
                        if lane:
                            try:
                                # è®¡ç®—ä¸»è½¦åœ¨æ­¤è½¦é“ä¸Šçš„ä½ç½®
                                local_coords = lane.local_coordinates(agent_pos)
                                longitudinal = local_coords[0]
                                lateral = local_coords[1]
                                
                                # æ£€æŸ¥ä¸»è½¦æ˜¯å¦åœ¨æ­¤è½¦é“ä¸Š
                                is_on_lane = (0 <= longitudinal <= lane.length) and (abs(lateral) < 5)
                                
                                if is_on_lane:
                                    # è®¡ç®—è·ç¦»è½¦é“ä¸­å¿ƒçš„è·ç¦»ä½œä¸ºä¼˜å…ˆçº§
                                    distance = abs(lateral)
                                    if distance < min_distance:
                                        min_distance = distance
                                        best_lane = lane
                                        
                            except Exception as e:
                                continue
            
            if best_lane:
                print(f"âœ… æ‰¾åˆ°æ­£ç¡®è½¦é“: {best_lane.index}")
                print(f"ğŸ¯ è½¦é“ä½ç½®: ({best_lane.position(0, 0)[0]:.1f}, {best_lane.position(0, 0)[1]:.1f}) â†’ ({best_lane.position(best_lane.length, 0)[0]:.1f}, {best_lane.position(best_lane.length, 0)[1]:.1f})")
                
                # 1. å¼ºåˆ¶æ›´æ–°å½“å‰è½¦é“
                navigation._current_lane = best_lane
                
                # 2. æ›´æ–°å‚è€ƒè½¦é“ - è¿™æ˜¯æ£€æŸ¥ç‚¹è®¡ç®—çš„åŸºç¡€
                navigation.current_ref_lanes = [best_lane]
                print(f"âœ… æ›´æ–°å½“å‰å‚è€ƒè½¦é“: {best_lane.index}")
                
                # 3. å¯»æ‰¾ä¸‹ä¸€ä¸ªè½¦é“ä½œä¸ºnext_ref_lanes
                next_lane = self._find_next_lane(best_lane, road_network)
                if next_lane:
                    navigation.next_ref_lanes = [next_lane]
                    print(f"âœ… æ›´æ–°ä¸‹ä¸€ä¸ªå‚è€ƒè½¦é“: {next_lane.index}")
                else:
                    navigation.next_ref_lanes = [best_lane]  # å¦‚æœæ²¡æœ‰ä¸‹ä¸€ä¸ªè½¦é“ï¼Œä½¿ç”¨å½“å‰è½¦é“
                    print(f"âš ï¸ æœªæ‰¾åˆ°ä¸‹ä¸€ä¸ªè½¦é“ï¼Œä½¿ç”¨å½“å‰è½¦é“")
                
                # 4. é‡ç½®æ£€æŸ¥ç‚¹ç´¢å¼•
                if hasattr(navigation, '_target_checkpoints_index'):
                    navigation._target_checkpoints_index = [0, 1]
                    print(f"âœ… é‡ç½®æ£€æŸ¥ç‚¹ç´¢å¼•: [0, 1]")
                
                # 5. æ›´æ–°å¯¼èˆªçŠ¶æ€
                navigation.update_localization(agent)
                
                print(f"âœ… è½¦é“æ£€æµ‹å’Œå¯¼èˆªè·¯å¾„ä¿®å¤æˆåŠŸ!")
                return True
            else:
                print(f"âŒ æ— æ³•æ‰¾åˆ°ä¸»è½¦æ‰€åœ¨çš„æ­£ç¡®è½¦é“")
                return False
                
        except Exception as e:
            print(f"âŒ è½¦é“æ£€æµ‹ä¿®å¤å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•CSVè·¯å¾„
    csv_path = "/home/jxy/æ¡Œé¢/1_Project/20250705_computational_cognitive_modeling/computational_cognitive_modeling/metadrive/a_scen_env/scenario_vehicles_9_0_1_2_3_4_5_6_7_8_test3_20250304_150943_row001_filtered.csv"
    
    # åŠ è½½è½¨è¿¹æ•°æ®
    traj_data = load_trajectory(
        csv_path=csv_path,
        normalize_position=False,
        max_duration=100,
        use_original_position=False,
        translate_to_origin=True,
        target_fps=50.0,
        use_original_timestamps=True
    )
    
    print(f"\nåŠ è½½äº† {len(traj_data)} è¾†è½¦çš„è½¨è¿¹æ•°æ®")
    print(f"è½¦è¾†ID: {list(traj_data.keys())}")
    
    # è®¤çŸ¥æ¨¡å—é…ç½®
    COGNITIVE_CONFIG = {
        'perception': {
            'enable': True,
            'sigma': 0.3,
            'enable_kalman': True,
            'process_noise': 0.1,
            'dt': 0.02
        },
        'cognitive_bias': {
            'enable': True,  # å¯ç”¨è®¤çŸ¥åå·®æ¨¡å—
            'inverse_tta_coef': 1.5,  # TTAåå·®ç³»æ•°
            'tta_threshold': 1.0,  # TTAé˜ˆå€¼ï¼ˆé™ä½ä»¥ä¾¿æ›´å®¹æ˜“è§¦å‘è§†è§‰åŒæ¶ï¼‰
            'adaptive_bias': True,  # å¯ç”¨è‡ªé€‚åº”åå·®
            'adaptation_rate': 0.01,
            'min_adaptive_factor': 0.5,
            'max_adaptive_factor': 2.0,
            'verbose': True,  # å¼€å¯è¯¦ç»†æ—¥å¿—æŸ¥çœ‹è§†è§‰åŒæ¶æ•ˆæœ
            
            # è§†è§‰åŒæ¶å‚æ•°
            'visual_detection_distance': 50.0,  # æ£€æµ‹è·ç¦»50ç±³
            'visual_detection_angle': 30.0,     # è½¦å¤´æ–¹å‘Â±30åº¦
            'visual_aversion_strength': 0.8     # è§†è§‰åŒæ¶å¼ºåº¦
        },
        'delay': {
            'enable': True,
            'delay_steps': 2,
            'enable_smoothing': True,
            'smoothing_factor': 0.3
        }
    }
    
    # åˆ›å»ºè®¤çŸ¥ç¯å¢ƒ
    env = TrajectoryReplayEnvCognitive(
        traj_data,
        config={
            'use_render': True,
            'manual_control': True,
            'enable_background_vehicles': True,
            'background_vehicle_update_mode': "position",
            'enable_realtime': True,
            'target_fps': 50.0,
            
            # å¯ç”¨è®¤çŸ¥æ¨¡å—
            'enable_cognitive_modules': True,
            'cognitive_config': COGNITIVE_CONFIG
        }
    )
    
    obs = env.reset()
    
    print("\nç¯å¢ƒå·²åˆå§‹åŒ–")
    print("ä¸»è½¦ä½ç½®:", env.agent.position)
    print("æ§åˆ¶æ¨¡å¼: PPO Expert (é»˜è®¤)")
    print("\nå¿«æ·é”®è¯´æ˜:")
    print("  T: åˆ‡æ¢ PPOä¸“å®¶/æ‰‹åŠ¨æ§åˆ¶ æ¨¡å¼")
    print("  E: å¼€å…³ PPOä¸“å®¶æ¥ç®¡")
    print("  R: å¼€å…³ è½¨è¿¹é‡æ”¾æ¨¡å¼")
    print("  W/A/S/D: æ‰‹åŠ¨æ§åˆ¶è½¦è¾†")
    print("\nè®¤çŸ¥æ¨¡å—ä»…åœ¨PPOä¸“å®¶æ¨¡å¼ä¸‹ç”Ÿæ•ˆ!")
    
    # ä¸»å¾ªç¯
    try:
        for i in range(1000):
            env.render()
            
            action = [0.0, 0.0]
            obs, reward, done, info = env.step(action)
            
            if i % 50 == 0:
                mode = info.get('Control Mode', 'unknown')
                cognitive_active = info.get('cognitive_modules_active', False)
                print(f"Step {i}: æ§åˆ¶æ¨¡å¼={mode}, è®¤çŸ¥æ¨¡å—={'æ¿€æ´»' if cognitive_active else 'æœªæ¿€æ´»'}, é€Ÿåº¦={env.agent.speed:.2f}")
            
            if done:
                print("ç¯å¢ƒç»“æŸ")
                break
                
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ï¼Œå…³é—­ç¯å¢ƒ...")
    finally:
        env.close() 